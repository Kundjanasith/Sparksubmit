for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S10_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/010_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S15_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/015_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S20_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/020_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S25_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/025_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S30_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/030_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S35_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/035_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S40_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/040_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S45_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/045_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S50_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/050_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S55_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/055_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S60_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/060_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S65_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/065_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S70_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/070_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S75_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/075_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S80_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/080_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S85_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/085_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S90_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/090_000_000/0$i.txt  & done

sleep 30m

for i in 1 2 3; do echo $i ;  hadoop fs -rmr /S* ; (  time spark-submit --class "S95_000_000_T" --master spark://sd-spark01.localdomain:7077 target/scala-2.10/spark-naist_2.10-1.0.jar --deploy-mode cluster )  2> log_paper/Core_effect/C1/Spark/095_000_000/0$i.txt  & done

