Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/06/28 15:23:36 INFO SparkContext: Running Spark version 1.6.0
17/06/28 15:23:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/06/28 15:23:36 INFO SecurityManager: Changing view acls to: hadoop
17/06/28 15:23:36 INFO SecurityManager: Changing modify acls to: hadoop
17/06/28 15:23:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)
17/06/28 15:23:37 INFO Utils: Successfully started service 'sparkDriver' on port 38962.
17/06/28 15:23:37 INFO Slf4jLogger: Slf4jLogger started
17/06/28 15:23:37 INFO Remoting: Starting remoting
17/06/28 15:23:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@163.221.29.42:39046]
17/06/28 15:23:37 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 39046.
17/06/28 15:23:37 INFO SparkEnv: Registering MapOutputTracker
17/06/28 15:23:37 INFO SparkEnv: Registering BlockManagerMaster
17/06/28 15:23:37 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-22cb3e30-d554-4106-9a86-d42564c56276
17/06/28 15:23:37 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/06/28 15:23:37 INFO SparkEnv: Registering OutputCommitCoordinator
17/06/28 15:23:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/06/28 15:23:37 INFO SparkUI: Started SparkUI at http://163.221.29.42:4040
17/06/28 15:23:37 INFO HttpFileServer: HTTP File server directory is /tmp/spark-b50314b6-138a-4be6-800d-cd1ac1417b28/httpd-36850bb1-00e1-46a4-98a9-44ca584f1dfa
17/06/28 15:23:37 INFO HttpServer: Starting HTTP Server
17/06/28 15:23:37 INFO Utils: Successfully started service 'HTTP file server' on port 45018.
17/06/28 15:23:37 INFO SparkContext: Added JAR file:/home/hadoop/code_spark/target/scala-2.10/spark-naist_2.10-1.0.jar at http://163.221.29.42:45018/jars/spark-naist_2.10-1.0.jar with timestamp 1498631017869
17/06/28 15:23:37 INFO AppClient$ClientEndpoint: Connecting to master spark://sd-spark01.localdomain:7077...
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20170628152338-0001
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/0 on worker-20170625193259-163.221.29.45-37695 (163.221.29.45:37695) with 8 cores
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/0 on hostPort 163.221.29.45:37695 with 8 cores, 1024.0 MB RAM
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/1 on worker-20170625193237-163.221.29.43-45839 (163.221.29.43:45839) with 8 cores
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/1 on hostPort 163.221.29.43:45839 with 8 cores, 1024.0 MB RAM
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/2 on worker-20170625193305-163.221.29.46-38968 (163.221.29.46:38968) with 8 cores
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/2 on hostPort 163.221.29.46:38968 with 8 cores, 1024.0 MB RAM
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/3 on worker-20170625193314-163.221.29.47-40335 (163.221.29.47:40335) with 8 cores
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/3 on hostPort 163.221.29.47:40335 with 8 cores, 1024.0 MB RAM
17/06/28 15:23:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44997.
17/06/28 15:23:38 INFO NettyBlockTransferService: Server created on 44997
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/4 on worker-20170625193251-163.221.29.44-34382 (163.221.29.44:34382) with 8 cores
17/06/28 15:23:38 INFO BlockManagerMaster: Trying to register BlockManager
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/4 on hostPort 163.221.29.44:34382 with 8 cores, 1024.0 MB RAM
17/06/28 15:23:38 INFO BlockManagerMasterEndpoint: Registering block manager 163.221.29.42:44997 with 511.1 MB RAM, BlockManagerId(driver, 163.221.29.42, 44997)
17/06/28 15:23:38 INFO BlockManagerMaster: Registered BlockManager
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/0 is now RUNNING
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/1 is now RUNNING
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/2 is now RUNNING
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/3 is now RUNNING
17/06/28 15:23:38 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/4 is now RUNNING
17/06/28 15:23:38 INFO EventLoggingListener: Logging events to hdfs://sd-spark01.localdomain:9000/eventLogging/app-20170628152338-0001
17/06/28 15:23:38 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/06/28 15:23:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.8 KB, free 208.8 KB)
17/06/28 15:23:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.4 KB, free 228.2 KB)
17/06/28 15:23:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 163.221.29.42:44997 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:38 INFO SparkContext: Created broadcast 0 from textFile at S90_000_000_T.scala:10
17/06/28 15:23:38 INFO FileInputFormat: Total input paths to process : 1
17/06/28 15:23:39 INFO NetworkTopology: Adding a new node: /default-rack/163.221.29.45:50010
17/06/28 15:23:39 INFO NetworkTopology: Adding a new node: /default-rack/163.221.29.46:50010
17/06/28 15:23:39 INFO NetworkTopology: Adding a new node: /default-rack/163.221.29.47:50010
17/06/28 15:23:39 INFO SparkContext: Starting job: count at ALS.scala:596
17/06/28 15:23:39 INFO DAGScheduler: Registering RDD 4 (mapPartitions at ALS.scala:837)
17/06/28 15:23:39 INFO DAGScheduler: Registering RDD 7 (map at ALS.scala:1080)
17/06/28 15:23:39 INFO DAGScheduler: Got job 0 (count at ALS.scala:596) with 5 output partitions
17/06/28 15:23:39 INFO DAGScheduler: Final stage: ResultStage 2 (count at ALS.scala:596)
17/06/28 15:23:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/06/28 15:23:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/06/28 15:23:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837), which has no missing parents
17/06/28 15:23:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 233.8 KB)
17/06/28 15:23:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 236.8 KB)
17/06/28 15:23:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 163.221.29.42:44997 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/06/28 15:23:39 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837)
17/06/28 15:23:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks
17/06/28 15:23:39 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark06.localdomain:59188) with ID 3
17/06/28 15:23:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, sd-spark06.localdomain, partition 0,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 1, sd-spark06.localdomain, partition 3,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 2, sd-spark06.localdomain, partition 4,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark06.localdomain:41832 with 511.1 MB RAM, BlockManagerId(3, sd-spark06.localdomain, 41832)
17/06/28 15:23:39 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 3, sd-spark06.localdomain, partition 7,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 4, sd-spark06.localdomain, partition 8,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark02.localdomain:53482) with ID 1
17/06/28 15:23:39 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, sd-spark02.localdomain, partition 5,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark05.localdomain:45218) with ID 2
17/06/28 15:23:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 6, sd-spark05.localdomain, partition 1,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 7, sd-spark05.localdomain, partition 6,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark04.localdomain:54230) with ID 0
17/06/28 15:23:39 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 8, sd-spark04.localdomain, partition 2,NODE_LOCAL, 2231 bytes)
17/06/28 15:23:39 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark02.localdomain:35201 with 511.1 MB RAM, BlockManagerId(1, sd-spark02.localdomain, 35201)
17/06/28 15:23:39 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark05.localdomain:40358 with 511.1 MB RAM, BlockManagerId(2, sd-spark05.localdomain, 40358)
17/06/28 15:23:39 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark04.localdomain:39985 with 511.1 MB RAM, BlockManagerId(0, sd-spark04.localdomain, 39985)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark06.localdomain:41832 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark02.localdomain:35201 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark04.localdomain:39985 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark05.localdomain:40358 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark02.localdomain:35201 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark04.localdomain:39985 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark06.localdomain:41832 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark05.localdomain:40358 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:40 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark03.localdomain:42962) with ID 4
17/06/28 15:23:40 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark03.localdomain:45654 with 511.1 MB RAM, BlockManagerId(4, sd-spark03.localdomain, 45654)
17/06/28 15:23:42 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, sd-spark03.localdomain, partition 9,ANY, 2231 bytes)
17/06/28 15:23:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark03.localdomain:45654 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:23:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark03.localdomain:45654 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:23:50 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 11201 ms on sd-spark02.localdomain (1/10)
17/06/28 15:23:50 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 8) in 11200 ms on sd-spark04.localdomain (2/10)
17/06/28 15:23:52 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 6) in 13186 ms on sd-spark05.localdomain (3/10)
17/06/28 15:23:52 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 7) in 13185 ms on sd-spark05.localdomain (4/10)
17/06/28 15:23:54 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14892 ms on sd-spark06.localdomain (5/10)
17/06/28 15:23:54 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 4) in 14881 ms on sd-spark06.localdomain (6/10)
17/06/28 15:23:54 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 3) in 14979 ms on sd-spark06.localdomain (7/10)
17/06/28 15:23:54 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 1) in 14987 ms on sd-spark06.localdomain (8/10)
17/06/28 15:23:54 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 2) in 15063 ms on sd-spark06.localdomain (9/10)
17/06/28 15:23:55 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 12361 ms on sd-spark03.localdomain (10/10)
17/06/28 15:23:55 INFO DAGScheduler: ShuffleMapStage 0 (mapPartitions at ALS.scala:837) finished in 16.137 s
17/06/28 15:23:55 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/06/28 15:23:55 INFO DAGScheduler: looking for newly runnable stages
17/06/28 15:23:55 INFO DAGScheduler: running: Set()
17/06/28 15:23:55 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
17/06/28 15:23:55 INFO DAGScheduler: failed: Set()
17/06/28 15:23:55 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080), which has no missing parents
17/06/28 15:23:55 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 243.6 KB)
17/06/28 15:23:55 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 247.1 KB)
17/06/28 15:23:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 163.221.29.42:44997 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:23:55 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/06/28 15:23:55 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080)
17/06/28 15:23:55 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/06/28 15:23:55 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, sd-spark05.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, sd-spark06.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, sd-spark05.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, sd-spark06.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, sd-spark05.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 15, sd-spark06.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 16, sd-spark05.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 17, sd-spark06.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 18, sd-spark06.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 19, sd-spark06.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:23:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark06.localdomain:41832 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:23:55 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark05.localdomain:40358 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark06.localdomain:59188
17/06/28 15:23:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45218
17/06/28 15:23:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 221 bytes
17/06/28 15:23:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 221 bytes
17/06/28 15:23:56 INFO BlockManagerInfo: Added rdd_6_4 in memory on sd-spark05.localdomain:40358 (size: 37.9 MB, free: 473.2 MB)
17/06/28 15:23:56 INFO BlockManagerInfo: Added rdd_6_0 in memory on sd-spark05.localdomain:40358 (size: 37.8 MB, free: 435.4 MB)
17/06/28 15:23:57 INFO BlockManagerInfo: Added rdd_6_8 in memory on sd-spark06.localdomain:41832 (size: 38.8 MB, free: 472.3 MB)
17/06/28 15:23:57 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 14) in 2299 ms on sd-spark05.localdomain (1/10)
17/06/28 15:23:57 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 2307 ms on sd-spark05.localdomain (2/10)
17/06/28 15:23:57 INFO BlockManagerInfo: Added rdd_6_2 in memory on sd-spark05.localdomain:40358 (size: 126.1 MB, free: 309.3 MB)
17/06/28 15:23:59 WARN TaskSetManager: Lost task 9.0 in stage 1.0 (TID 19, sd-spark06.localdomain): java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:448)
	at scala.collection.mutable.ArrayBuilder$ofFloat.result(ArrayBuilder.scala:493)
	at scala.collection.mutable.ArrayBuilder$ofFloat.result(ArrayBuilder.scala:441)
	at org.apache.spark.ml.recommendation.ALS$RatingBlockBuilder.build(ALS.scala:808)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:861)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:858)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:283)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/06/28 15:23:59 INFO TaskSetManager: Starting task 9.1 in stage 1.0 (TID 20, sd-spark06.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:00 ERROR TaskSchedulerImpl: Lost executor 3 on sd-spark06.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/3 is now EXITED (Command exited with code 52)
17/06/28 15:24:00 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/3 removed: Command exited with code 52
17/06/28 15:24:00 WARN TaskSetManager: Lost task 7.0 in stage 1.0 (TID 17, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 WARN TaskSetManager: Lost task 9.1 in stage 1.0 (TID 20, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 WARN TaskSetManager: Lost task 1.0 in stage 1.0 (TID 11, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 WARN TaskSetManager: Lost task 3.0 in stage 1.0 (TID 13, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 WARN TaskSetManager: Lost task 8.0 in stage 1.0 (TID 18, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 WARN TaskSetManager: Lost task 5.0 in stage 1.0 (TID 15, sd-spark06.localdomain): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:00 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 3
17/06/28 15:24:00 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/5 on worker-20170625193314-163.221.29.47-40335 (163.221.29.47:40335) with 8 cores
17/06/28 15:24:00 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/5 on hostPort 163.221.29.47:40335 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:00 INFO TaskSetManager: Starting task 5.1 in stage 1.0 (TID 21, sd-spark05.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:00 INFO TaskSetManager: Starting task 3.1 in stage 1.0 (TID 22, sd-spark05.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:00 INFO TaskSetManager: Starting task 1.1 in stage 1.0 (TID 23, sd-spark05.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:00 INFO DAGScheduler: Executor lost: 3 (epoch 1)
17/06/28 15:24:00 INFO BlockManagerMasterEndpoint: Trying to remove executor 3 from BlockManagerMaster.
17/06/28 15:24:00 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(3, sd-spark06.localdomain, 41832)
17/06/28 15:24:00 INFO BlockManagerMaster: Removed 3 successfully in removeExecutor
17/06/28 15:24:00 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 3 (5/10, false)
17/06/28 15:24:00 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/5 is now RUNNING
17/06/28 15:24:01 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark06.localdomain:59226) with ID 5
17/06/28 15:24:01 INFO TaskSetManager: Starting task 8.1 in stage 1.0 (TID 24, sd-spark06.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:01 INFO TaskSetManager: Starting task 9.2 in stage 1.0 (TID 25, sd-spark06.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:01 INFO TaskSetManager: Starting task 7.1 in stage 1.0 (TID 26, sd-spark06.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:01 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark06.localdomain:46801 with 511.1 MB RAM, BlockManagerId(5, sd-spark06.localdomain, 46801)
17/06/28 15:24:05 INFO TaskSetManager: Lost task 5.1 in stage 1.0 (TID 21) on executor sd-spark05.localdomain: java.lang.OutOfMemoryError (Java heap space) [duplicate 1]
17/06/28 15:24:05 INFO TaskSetManager: Starting task 5.2 in stage 1.0 (TID 27, sd-spark05.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 WARN TaskSetManager: Lost task 1.1 in stage 1.0 (TID 23, sd-spark05.localdomain): java.lang.OutOfMemoryError: GC overhead limit exceeded
	at java.lang.reflect.Array.newInstance(Array.java:75)
	at java.io.ObjectInputStream.readArray(ObjectInputStream.java:1897)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1529)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:2245)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:2169)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:2027)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1535)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:422)
	at org.apache.spark.serializer.JavaDeserializationStream.readObject(JavaSerializer.scala:76)
	at org.apache.spark.serializer.DeserializationStream.readValue(Serializer.scala:171)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:201)
	at org.apache.spark.serializer.DeserializationStream$$anon$2.getNext(Serializer.scala:198)
	at org.apache.spark.util.NextIterator.hasNext(NextIterator.scala:73)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)

17/06/28 15:24:05 INFO TaskSetManager: Starting task 1.2 in stage 1.0 (TID 28, sd-spark06.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 INFO TaskSetManager: Lost task 6.0 in stage 1.0 (TID 16) on executor sd-spark05.localdomain: java.lang.OutOfMemoryError (Java heap space) [duplicate 2]
17/06/28 15:24:05 INFO TaskSetManager: Starting task 6.1 in stage 1.0 (TID 29, sd-spark06.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 ERROR TaskSchedulerImpl: Lost executor 2 on sd-spark05.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:05 WARN TaskSetManager: Lost task 3.1 in stage 1.0 (TID 22, sd-spark05.localdomain): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:05 WARN TaskSetManager: Lost task 5.2 in stage 1.0 (TID 27, sd-spark05.localdomain): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:05 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 12, sd-spark05.localdomain): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:05 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 4), so marking it as still running
17/06/28 15:24:05 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 0), so marking it as still running
17/06/28 15:24:05 INFO TaskSetManager: Starting task 2.1 in stage 1.0 (TID 30, sd-spark06.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/2 is now EXITED (Command exited with code 52)
17/06/28 15:24:05 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/2 removed: Command exited with code 52
17/06/28 15:24:05 INFO TaskSetManager: Starting task 5.3 in stage 1.0 (TID 31, sd-spark06.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 INFO TaskSetManager: Starting task 3.2 in stage 1.0 (TID 32, sd-spark06.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:05 INFO DAGScheduler: Executor lost: 2 (epoch 3)
17/06/28 15:24:05 INFO BlockManagerMasterEndpoint: Trying to remove executor 2 from BlockManagerMaster.
17/06/28 15:24:05 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(2, sd-spark05.localdomain, 40358)
17/06/28 15:24:05 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 2
17/06/28 15:24:05 INFO BlockManagerMaster: Removed 2 successfully in removeExecutor
17/06/28 15:24:05 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/6 on worker-20170625193305-163.221.29.46-38968 (163.221.29.46:38968) with 8 cores
17/06/28 15:24:05 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/6 on hostPort 163.221.29.46:38968 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:05 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 2 (3/10, false)
17/06/28 15:24:05 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 2 (0/10, false)
17/06/28 15:24:05 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/6 is now RUNNING
17/06/28 15:24:07 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark05.localdomain:45262) with ID 6
17/06/28 15:24:07 INFO TaskSetManager: Starting task 0.1 in stage 1.0 (TID 33, sd-spark05.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 4.1 in stage 1.0 (TID 34, sd-spark05.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:07 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark05.localdomain:38627 with 511.1 MB RAM, BlockManagerId(6, sd-spark05.localdomain, 38627)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark05.localdomain:38627 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45262
17/06/28 15:24:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 196 bytes
17/06/28 15:24:07 WARN TaskSetManager: Lost task 4.1 in stage 1.0 (TID 34, sd-spark05.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=4, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:07 WARN TaskSetManager: Lost task 0.1 in stage 1.0 (TID 33, sd-spark05.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=0, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:07 INFO DAGScheduler: Marking ShuffleMapStage 1 (map at ALS.scala:1080) as failed due to a fetch failure from ShuffleMapStage 0 (mapPartitions at ALS.scala:837)
17/06/28 15:24:07 INFO DAGScheduler: ShuffleMapStage 1 (map at ALS.scala:1080) failed in 12.252 s
17/06/28 15:24:07 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:24:07 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:24:07 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837), which has no missing parents
17/06/28 15:24:07 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.6 KB, free 252.8 KB)
17/06/28 15:24:07 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.0 KB, free 255.8 KB)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 163.221.29.42:44997 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:07 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/06/28 15:24:07 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837)
17/06/28 15:24:07 INFO TaskSchedulerImpl: Adding task set 0.1 with 7 tasks
17/06/28 15:24:07 INFO TaskSetManager: Starting task 2.0 in stage 0.1 (TID 35, sd-spark02.localdomain, partition 3,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 1.0 in stage 0.1 (TID 36, sd-spark03.localdomain, partition 1,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 0.0 in stage 0.1 (TID 37, sd-spark05.localdomain, partition 0,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 4.0 in stage 0.1 (TID 38, sd-spark03.localdomain, partition 6,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 3.0 in stage 0.1 (TID 39, sd-spark05.localdomain, partition 4,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 5.0 in stage 0.1 (TID 40, sd-spark03.localdomain, partition 7,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO TaskSetManager: Starting task 6.0 in stage 0.1 (TID 41, sd-spark03.localdomain, partition 8,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sd-spark03.localdomain:45654 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sd-spark02.localdomain:35201 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sd-spark05.localdomain:38627 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark05.localdomain:38627 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:24:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark06.localdomain:46801 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:18 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark06.localdomain:59226
17/06/28 15:24:18 WARN TaskSetManager: Lost task 1.2 in stage 1.0 (TID 28, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=1, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:24:18 WARN TaskSetManager: Lost task 6.1 in stage 1.0 (TID 29, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=6, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 WARN TaskSetManager: Lost task 9.2 in stage 1.0 (TID 25, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 WARN TaskSetManager: Lost task 5.3 in stage 1.0 (TID 31, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=5, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 WARN TaskSetManager: Lost task 8.1 in stage 1.0 (TID 24, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 WARN TaskSetManager: Lost task 2.1 in stage 1.0 (TID 30, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=2, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 WARN TaskSetManager: Lost task 3.2 in stage 1.0 (TID 32, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=3, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/06/28 15:24:18 WARN TaskSetManager: Lost task 7.1 in stage 1.0 (TID 26, sd-spark06.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:18 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/06/28 15:24:18 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:24:18 INFO TaskSetManager: Finished task 2.0 in stage 0.1 (TID 35) in 10620 ms on sd-spark02.localdomain (1/7)
17/06/28 15:24:19 INFO TaskSetManager: Finished task 3.0 in stage 0.1 (TID 39) in 11886 ms on sd-spark05.localdomain (2/7)
17/06/28 15:24:19 INFO TaskSetManager: Finished task 0.0 in stage 0.1 (TID 37) in 11888 ms on sd-spark05.localdomain (3/7)
17/06/28 15:24:20 INFO TaskSetManager: Finished task 4.0 in stage 0.1 (TID 38) in 12792 ms on sd-spark03.localdomain (4/7)
17/06/28 15:24:20 INFO TaskSetManager: Finished task 1.0 in stage 0.1 (TID 36) in 12891 ms on sd-spark03.localdomain (5/7)
17/06/28 15:24:20 INFO TaskSetManager: Finished task 6.0 in stage 0.1 (TID 41) in 12973 ms on sd-spark03.localdomain (6/7)
17/06/28 15:24:20 INFO TaskSetManager: Finished task 5.0 in stage 0.1 (TID 40) in 13181 ms on sd-spark03.localdomain (7/7)
17/06/28 15:24:20 INFO TaskSchedulerImpl: Removed TaskSet 0.1, whose tasks have all completed, from pool 
17/06/28 15:24:20 INFO DAGScheduler: ShuffleMapStage 0 (mapPartitions at ALS.scala:837) finished in 13.184 s
17/06/28 15:24:20 INFO DAGScheduler: looking for newly runnable stages
17/06/28 15:24:20 INFO DAGScheduler: running: Set()
17/06/28 15:24:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
17/06/28 15:24:20 INFO DAGScheduler: failed: Set()
17/06/28 15:24:20 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080), which has no missing parents
17/06/28 15:24:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.8 KB, free 262.6 KB)
17/06/28 15:24:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.5 KB, free 266.0 KB)
17/06/28 15:24:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 163.221.29.42:44997 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/06/28 15:24:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080)
17/06/28 15:24:20 INFO TaskSchedulerImpl: Adding task set 1.1 with 10 tasks
17/06/28 15:24:20 INFO TaskSetManager: Starting task 0.0 in stage 1.1 (TID 42, sd-spark05.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 1.0 in stage 1.1 (TID 43, sd-spark02.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 2.0 in stage 1.1 (TID 44, sd-spark03.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 3.0 in stage 1.1 (TID 45, sd-spark05.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 4.0 in stage 1.1 (TID 46, sd-spark02.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 5.0 in stage 1.1 (TID 47, sd-spark03.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 6.0 in stage 1.1 (TID 48, sd-spark05.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 7.0 in stage 1.1 (TID 49, sd-spark03.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 8.0 in stage 1.1 (TID 50, sd-spark03.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO TaskSetManager: Starting task 9.0 in stage 1.1 (TID 51, sd-spark03.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sd-spark05.localdomain:38627 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sd-spark02.localdomain:35201 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sd-spark03.localdomain:45654 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:20 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45262
17/06/28 15:24:20 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 213 bytes
17/06/28 15:24:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark03.localdomain:42962
17/06/28 15:24:21 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark02.localdomain:53482
17/06/28 15:24:21 INFO BlockManagerInfo: Added rdd_6_4 in memory on sd-spark02.localdomain:35201 (size: 37.9 MB, free: 473.2 MB)
17/06/28 15:24:21 INFO BlockManagerInfo: Added rdd_6_0 in memory on sd-spark05.localdomain:38627 (size: 37.8 MB, free: 473.3 MB)
17/06/28 15:24:22 INFO BlockManagerInfo: Added rdd_6_1 in memory on sd-spark02.localdomain:35201 (size: 86.2 MB, free: 387.0 MB)
17/06/28 15:24:22 INFO TaskSetManager: Finished task 4.0 in stage 1.1 (TID 46) in 1504 ms on sd-spark02.localdomain (1/10)
17/06/28 15:24:22 INFO TaskSetManager: Finished task 0.0 in stage 1.1 (TID 42) in 1578 ms on sd-spark05.localdomain (2/10)
17/06/28 15:24:22 INFO BlockManagerInfo: Added rdd_6_9 in memory on sd-spark03.localdomain:45654 (size: 46.9 MB, free: 464.2 MB)
17/06/28 15:24:22 INFO BlockManagerInfo: Added rdd_6_8 in memory on sd-spark03.localdomain:45654 (size: 38.8 MB, free: 425.3 MB)
17/06/28 15:24:23 INFO TaskSetManager: Finished task 1.0 in stage 1.1 (TID 43) in 2664 ms on sd-spark02.localdomain (3/10)
17/06/28 15:24:23 INFO BlockManagerInfo: Added rdd_6_5 in memory on sd-spark03.localdomain:45654 (size: 77.9 MB, free: 347.4 MB)
17/06/28 15:24:25 INFO TaskSetManager: Finished task 8.0 in stage 1.1 (TID 50) in 4092 ms on sd-spark03.localdomain (4/10)
17/06/28 15:24:25 INFO TaskSetManager: Finished task 9.0 in stage 1.1 (TID 51) in 4248 ms on sd-spark03.localdomain (5/10)
17/06/28 15:24:25 WARN TaskSetManager: Lost task 3.0 in stage 1.1 (TID 45, sd-spark05.localdomain): java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ArrayBuilder$ofInt.mkArray(ArrayBuilder.scala:320)
	at scala.collection.mutable.ArrayBuilder$ofInt.resize(ArrayBuilder.scala:326)
	at scala.collection.mutable.ArrayBuilder$ofInt.ensureSize(ArrayBuilder.scala:338)
	at scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:343)
	at scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:313)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuilder$ofInt.$plus$plus$eq(ArrayBuilder.scala:356)
	at scala.collection.mutable.ArrayBuilder$ofInt.$plus$plus$eq(ArrayBuilder.scala:313)
	at org.apache.spark.ml.recommendation.ALS$RatingBlockBuilder.merge(ALS.scala:801)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2$$anonfun$apply$8.apply(ALS.scala:860)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2$$anonfun$apply$8.apply(ALS.scala:860)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:30)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:860)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:858)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$12.next(Iterator.scala:357)
	at org.apache.spark.serializer.SerializationStream.writeAll(Serializer.scala:153)
	at org.apache.spark.storage.BlockManager.dataSerializeStream(BlockManager.scala:1196)
	at org.apache.spark.storage.DiskStore$$anonfun$putIterator$1.apply$mcV$sp(DiskStore.scala:81)
	at org.apache.spark.storage.DiskStore$$anonfun$putIterator$1.apply(DiskStore.scala:81)
	at org.apache.spark.storage.DiskStore$$anonfun$putIterator$1.apply(DiskStore.scala:81)
	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1250)
	at org.apache.spark.storage.DiskStore.putIterator(DiskStore.scala:82)

17/06/28 15:24:25 INFO TaskSetManager: Starting task 3.1 in stage 1.1 (TID 52, sd-spark02.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:25 ERROR TaskSchedulerImpl: Lost executor 6 on sd-spark05.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:25 WARN TaskSetManager: Lost task 6.0 in stage 1.1 (TID 48, sd-spark05.localdomain): ExecutorLostFailure (executor 6 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:25 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 0), so marking it as still running
17/06/28 15:24:25 INFO DAGScheduler: Executor lost: 6 (epoch 6)
17/06/28 15:24:25 INFO TaskSetManager: Starting task 6.1 in stage 1.1 (TID 53, sd-spark02.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:25 INFO BlockManagerMasterEndpoint: Trying to remove executor 6 from BlockManagerMaster.
17/06/28 15:24:25 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(6, sd-spark05.localdomain, 38627)
17/06/28 15:24:25 INFO TaskSetManager: Starting task 0.1 in stage 1.1 (TID 54, sd-spark03.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:25 INFO BlockManagerMaster: Removed 6 successfully in removeExecutor
17/06/28 15:24:25 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 6 (8/10, false)
17/06/28 15:24:25 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 6 (4/10, false)
17/06/28 15:24:25 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/6 is now EXITED (Command exited with code 52)
17/06/28 15:24:25 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/6 removed: Command exited with code 52
17/06/28 15:24:25 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 6
17/06/28 15:24:25 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/7 on worker-20170625193305-163.221.29.46-38968 (163.221.29.46:38968) with 8 cores
17/06/28 15:24:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/7 on hostPort 163.221.29.46:38968 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:25 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/7 is now RUNNING
17/06/28 15:24:27 INFO TaskSetManager: Lost task 7.0 in stage 1.1 (TID 49) on executor sd-spark03.localdomain: java.lang.OutOfMemoryError (Java heap space) [duplicate 1]
17/06/28 15:24:27 INFO TaskSetManager: Starting task 7.1 in stage 1.1 (TID 55, sd-spark03.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:27 WARN TaskSetManager: Lost task 7.1 in stage 1.1 (TID 55, sd-spark03.localdomain): FetchFailed(BlockManagerId(4, sd-spark03.localdomain, 45654), shuffleId=1, mapId=1, reduceId=7, message=
org.apache.spark.shuffle.FetchFailedException: /tmp/spark-8ea09063-0a73-41b0-a1f6-19008d9465f3/executor-c2f07d05-daf5-4351-88a9-0075d177a98d/blockmgr-be9cf656-cd2f-4fdb-9316-c2620c26f5ae/32/shuffle_1_1_0.index (No such file or directory)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.FileNotFoundException: /tmp/spark-8ea09063-0a73-41b0-a1f6-19008d9465f3/executor-c2f07d05-daf5-4351-88a9-0075d177a98d/blockmgr-be9cf656-cd2f-4fdb-9316-c2620c26f5ae/32/shuffle_1_1_0.index (No such file or directory)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(FileInputStream.java:195)
	at java.io.FileInputStream.<init>(FileInputStream.java:138)
	at org.apache.spark.shuffle.IndexShuffleBlockResolver.getBlockData(IndexShuffleBlockResolver.scala:191)
	at org.apache.spark.storage.BlockManager.getBlockData(BlockManager.scala:291)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.fetchLocalBlocks(ShuffleBlockFetcherIterator.scala:238)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.initialize(ShuffleBlockFetcherIterator.scala:269)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.<init>(ShuffleBlockFetcherIterator.scala:112)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:43)
	... 17 more

)
17/06/28 15:24:27 INFO DAGScheduler: Marking ShuffleMapStage 1 (map at ALS.scala:1080) as failed due to a fetch failure from ShuffleMapStage 0 (mapPartitions at ALS.scala:837)
17/06/28 15:24:27 INFO DAGScheduler: ShuffleMapStage 1 (map at ALS.scala:1080) failed in 6.332 s
17/06/28 15:24:27 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:24:27 INFO DAGScheduler: Executor lost: 4 (epoch 6)
17/06/28 15:24:27 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/06/28 15:24:27 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(4, sd-spark03.localdomain, 45654)
17/06/28 15:24:27 INFO BlockManagerMaster: Removed 4 successfully in removeExecutor
17/06/28 15:24:27 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 4 (3/10, false)
17/06/28 15:24:27 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 4 (2/10, false)
17/06/28 15:24:27 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:24:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837), which has no missing parents
17/06/28 15:24:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 5.6 KB, free 271.7 KB)
17/06/28 15:24:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.0 KB, free 274.7 KB)
17/06/28 15:24:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 163.221.29.42:44997 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/06/28 15:24:27 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837)
17/06/28 15:24:27 INFO TaskSchedulerImpl: Adding task set 0.2 with 7 tasks
17/06/28 15:24:27 INFO TaskSetManager: Starting task 0.0 in stage 0.2 (TID 56, sd-spark06.localdomain, partition 0,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 1.0 in stage 0.2 (TID 57, sd-spark03.localdomain, partition 1,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 2.0 in stage 0.2 (TID 58, sd-spark06.localdomain, partition 4,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 3.0 in stage 0.2 (TID 59, sd-spark03.localdomain, partition 6,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 4.0 in stage 0.2 (TID 60, sd-spark06.localdomain, partition 7,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 5.0 in stage 0.2 (TID 61, sd-spark03.localdomain, partition 8,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark05.localdomain:45286) with ID 7
17/06/28 15:24:27 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark05.localdomain:35038 with 511.1 MB RAM, BlockManagerId(7, sd-spark05.localdomain, 35038)
17/06/28 15:24:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sd-spark06.localdomain:46801 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark06.localdomain:46801 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:24:27 WARN TransportChannelHandler: Exception in connection from sd-spark03.localdomain/163.221.29.44:42962
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:192)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at io.netty.buffer.PooledUnsafeDirectByteBuf.setBytes(PooledUnsafeDirectByteBuf.java:313)
	at io.netty.buffer.AbstractByteBuf.writeBytes(AbstractByteBuf.java:881)
	at io.netty.channel.socket.nio.NioSocketChannel.doReadBytes(NioSocketChannel.java:242)
	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:119)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	at java.lang.Thread.run(Thread.java:748)
17/06/28 15:24:27 ERROR TaskSchedulerImpl: Lost executor 4 on sd-spark03.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 8), so marking it as still running
17/06/28 15:24:27 WARN TaskSetManager: Lost task 2.0 in stage 1.1 (TID 44, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 WARN TaskSetManager: Lost task 5.0 in stage 1.1 (TID 47, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 7), so marking it as still running
17/06/28 15:24:27 WARN TaskSetManager: Lost task 0.1 in stage 1.1 (TID 54, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 9), so marking it as still running
17/06/28 15:24:27 WARN TaskSetManager: Lost task 3.0 in stage 0.2 (TID 59, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 WARN TaskSetManager: Lost task 5.0 in stage 0.2 (TID 61, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 WARN TaskSetManager: Lost task 1.0 in stage 0.2 (TID 57, sd-spark03.localdomain): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:27 INFO TaskSetManager: Starting task 5.1 in stage 0.2 (TID 62, sd-spark06.localdomain, partition 8,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO DAGScheduler: Executor lost: 4 (epoch 11)
17/06/28 15:24:27 INFO BlockManagerMasterEndpoint: Trying to remove executor 4 from BlockManagerMaster.
17/06/28 15:24:27 INFO BlockManagerMaster: Removed 4 successfully in removeExecutor
17/06/28 15:24:27 INFO TaskSetManager: Starting task 1.1 in stage 0.2 (TID 63, sd-spark05.localdomain, partition 1,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO TaskSetManager: Starting task 3.1 in stage 0.2 (TID 64, sd-spark05.localdomain, partition 6,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:27 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/4 is now EXITED (Command exited with code 52)
17/06/28 15:24:27 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/4 removed: Command exited with code 52
17/06/28 15:24:27 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 4
17/06/28 15:24:27 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/8 on worker-20170625193251-163.221.29.44-34382 (163.221.29.44:34382) with 8 cores
17/06/28 15:24:27 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/8 on hostPort 163.221.29.44:34382 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:27 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/8 is now RUNNING
17/06/28 15:24:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sd-spark05.localdomain:35038 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark05.localdomain:35038 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:24:29 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark03.localdomain:43006) with ID 8
17/06/28 15:24:29 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark03.localdomain:41102 with 511.1 MB RAM, BlockManagerId(8, sd-spark03.localdomain, 41102)
17/06/28 15:24:30 INFO TaskSetManager: Starting task 6.0 in stage 0.2 (TID 65, sd-spark06.localdomain, partition 9,ANY, 2231 bytes)
17/06/28 15:24:40 INFO TaskSetManager: Finished task 3.1 in stage 0.2 (TID 64) in 12547 ms on sd-spark05.localdomain (1/7)
17/06/28 15:24:40 INFO TaskSetManager: Finished task 1.1 in stage 0.2 (TID 63) in 12579 ms on sd-spark05.localdomain (2/7)
17/06/28 15:24:40 WARN TaskSetManager: Lost task 3.1 in stage 1.1 (TID 52, sd-spark02.localdomain): FetchFailed(BlockManagerId(6, sd-spark05.localdomain, 38627), shuffleId=1, mapId=0, reduceId=3, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to sd-spark05.localdomain/163.221.29.46:38627
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to sd-spark05.localdomain/163.221.29.46:38627
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
Caused by: java.net.ConnectException: Connection refused: sd-spark05.localdomain/163.221.29.46:38627
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more

)
17/06/28 15:24:40 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:24:40 WARN TaskSetManager: Lost task 6.1 in stage 1.1 (TID 53, sd-spark02.localdomain): FetchFailed(BlockManagerId(6, sd-spark05.localdomain, 38627), shuffleId=1, mapId=0, reduceId=6, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to sd-spark05.localdomain/163.221.29.46:38627
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to sd-spark05.localdomain/163.221.29.46:38627
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
Caused by: java.net.ConnectException: Connection refused: sd-spark05.localdomain/163.221.29.46:38627
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more

)
17/06/28 15:24:40 INFO TaskSchedulerImpl: Removed TaskSet 1.1, whose tasks have all completed, from pool 
17/06/28 15:24:41 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:24:43 INFO TaskSetManager: Finished task 5.1 in stage 0.2 (TID 62) in 15647 ms on sd-spark06.localdomain (3/7)
17/06/28 15:24:43 INFO TaskSetManager: Finished task 4.0 in stage 0.2 (TID 60) in 15821 ms on sd-spark06.localdomain (4/7)
17/06/28 15:24:43 INFO TaskSetManager: Finished task 0.0 in stage 0.2 (TID 56) in 15896 ms on sd-spark06.localdomain (5/7)
17/06/28 15:24:43 INFO TaskSetManager: Finished task 2.0 in stage 0.2 (TID 58) in 15997 ms on sd-spark06.localdomain (6/7)
17/06/28 15:24:45 INFO TaskSetManager: Finished task 6.0 in stage 0.2 (TID 65) in 14987 ms on sd-spark06.localdomain (7/7)
17/06/28 15:24:45 INFO DAGScheduler: ShuffleMapStage 0 (mapPartitions at ALS.scala:837) finished in 18.409 s
17/06/28 15:24:45 INFO DAGScheduler: looking for newly runnable stages
17/06/28 15:24:45 INFO TaskSchedulerImpl: Removed TaskSet 0.2, whose tasks have all completed, from pool 
17/06/28 15:24:45 INFO DAGScheduler: running: Set()
17/06/28 15:24:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
17/06/28 15:24:45 INFO DAGScheduler: failed: Set()
17/06/28 15:24:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080), which has no missing parents
17/06/28 15:24:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.8 KB, free 281.5 KB)
17/06/28 15:24:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.5 KB, free 285.0 KB)
17/06/28 15:24:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 163.221.29.42:44997 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/06/28 15:24:45 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080)
17/06/28 15:24:45 INFO TaskSchedulerImpl: Adding task set 1.2 with 8 tasks
17/06/28 15:24:45 INFO TaskSetManager: Starting task 0.0 in stage 1.2 (TID 66, sd-spark06.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 1.0 in stage 1.2 (TID 67, sd-spark02.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 2.0 in stage 1.2 (TID 68, sd-spark05.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 3.0 in stage 1.2 (TID 69, sd-spark06.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 4.0 in stage 1.2 (TID 70, sd-spark02.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 5.0 in stage 1.2 (TID 71, sd-spark06.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 6.0 in stage 1.2 (TID 72, sd-spark06.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO TaskSetManager: Starting task 7.0 in stage 1.2 (TID 73, sd-spark06.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark02.localdomain:35201 (size: 3.5 KB, free: 387.0 MB)
17/06/28 15:24:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark05.localdomain:35038 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark06.localdomain:46801 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark02.localdomain:53482
17/06/28 15:24:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 215 bytes
17/06/28 15:24:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark06.localdomain:59226
17/06/28 15:24:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45286
17/06/28 15:24:47 WARN TaskSetManager: Lost task 1.0 in stage 1.2 (TID 67, sd-spark02.localdomain): java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:448)
	at scala.collection.mutable.ArrayBuilder$ofFloat.result(ArrayBuilder.scala:493)
	at scala.collection.mutable.ArrayBuilder$ofFloat.result(ArrayBuilder.scala:441)
	at org.apache.spark.ml.recommendation.ALS$RatingBlockBuilder.build(ALS.scala:808)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:861)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:858)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:283)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

17/06/28 15:24:47 INFO TaskSetManager: Starting task 1.1 in stage 1.2 (TID 74, sd-spark02.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:47 ERROR TaskSchedulerImpl: Lost executor 1 on sd-spark02.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:47 WARN TaskSetManager: Lost task 1.1 in stage 1.2 (TID 74, sd-spark02.localdomain): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:47 WARN TaskSetManager: Lost task 4.0 in stage 1.2 (TID 70, sd-spark02.localdomain): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:47 INFO DAGScheduler: Executor lost: 1 (epoch 16)
17/06/28 15:24:47 INFO BlockManagerMasterEndpoint: Trying to remove executor 1 from BlockManagerMaster.
17/06/28 15:24:47 INFO TaskSetManager: Starting task 4.1 in stage 1.2 (TID 75, sd-spark06.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:47 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(1, sd-spark02.localdomain, 35201)
17/06/28 15:24:47 INFO TaskSetManager: Starting task 1.2 in stage 1.2 (TID 76, sd-spark05.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:24:47 INFO BlockManagerMaster: Removed 1 successfully in removeExecutor
17/06/28 15:24:47 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 1 (8/10, false)
17/06/28 15:24:47 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 1 (0/10, false)
17/06/28 15:24:47 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/1 is now EXITED (Command exited with code 52)
17/06/28 15:24:47 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/1 removed: Command exited with code 52
17/06/28 15:24:47 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 1
17/06/28 15:24:47 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/9 on worker-20170625193237-163.221.29.43-45839 (163.221.29.43:45839) with 8 cores
17/06/28 15:24:47 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/9 on hostPort 163.221.29.43:45839 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:47 INFO BlockManagerInfo: Added rdd_6_0 in memory on sd-spark06.localdomain:46801 (size: 37.8 MB, free: 473.3 MB)
17/06/28 15:24:47 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/9 is now RUNNING
17/06/28 15:24:48 INFO BlockManagerInfo: Added rdd_6_3 in memory on sd-spark05.localdomain:35038 (size: 210.0 MB, free: 301.1 MB)
17/06/28 15:24:48 INFO BlockManagerInfo: Added rdd_6_8 in memory on sd-spark06.localdomain:46801 (size: 38.8 MB, free: 434.4 MB)
17/06/28 15:24:48 INFO BlockManagerInfo: Added rdd_6_9 in memory on sd-spark06.localdomain:46801 (size: 46.9 MB, free: 387.5 MB)
17/06/28 15:24:49 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark02.localdomain:53548) with ID 9
17/06/28 15:24:49 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark02.localdomain:41630 with 511.1 MB RAM, BlockManagerId(9, sd-spark02.localdomain, 41630)
17/06/28 15:24:50 INFO BlockManagerInfo: Added rdd_6_5 in memory on sd-spark06.localdomain:46801 (size: 77.9 MB, free: 309.6 MB)
17/06/28 15:24:51 INFO TaskSetManager: Finished task 0.0 in stage 1.2 (TID 66) in 5362 ms on sd-spark06.localdomain (1/8)
17/06/28 15:24:51 INFO TaskSetManager: Finished task 6.0 in stage 1.2 (TID 72) in 5389 ms on sd-spark06.localdomain (2/8)
17/06/28 15:24:51 INFO TaskSetManager: Finished task 2.0 in stage 1.2 (TID 68) in 5678 ms on sd-spark05.localdomain (3/8)
17/06/28 15:24:51 INFO TaskSetManager: Finished task 7.0 in stage 1.2 (TID 73) in 5783 ms on sd-spark06.localdomain (4/8)
17/06/28 15:24:55 INFO TaskSetManager: Lost task 5.0 in stage 1.2 (TID 71) on executor sd-spark06.localdomain: java.lang.OutOfMemoryError (Java heap space) [duplicate 1]
17/06/28 15:24:55 INFO TaskSetManager: Starting task 5.1 in stage 1.2 (TID 77, sd-spark02.localdomain, partition 7,ANY, 1949 bytes)
17/06/28 15:24:55 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark02.localdomain:41630 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:24:55 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark02.localdomain:53548
17/06/28 15:24:55 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 206 bytes
17/06/28 15:24:55 WARN TaskSetManager: Lost task 5.1 in stage 1.2 (TID 77, sd-spark02.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:24:55 INFO DAGScheduler: Marking ShuffleMapStage 1 (map at ALS.scala:1080) as failed due to a fetch failure from ShuffleMapStage 0 (mapPartitions at ALS.scala:837)
17/06/28 15:24:55 INFO DAGScheduler: ShuffleMapStage 1 (map at ALS.scala:1080) failed in 9.720 s
17/06/28 15:24:55 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:24:55 ERROR TaskSchedulerImpl: Lost executor 5 on sd-spark06.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:55 WARN TaskSetManager: Lost task 3.0 in stage 1.2 (TID 69, sd-spark06.localdomain): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:55 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 7), so marking it as still running
17/06/28 15:24:55 WARN TaskSetManager: Lost task 4.1 in stage 1.2 (TID 75, sd-spark06.localdomain): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:24:55 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 9), so marking it as still running
17/06/28 15:24:55 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 8), so marking it as still running
17/06/28 15:24:55 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 0), so marking it as still running
17/06/28 15:24:55 INFO DAGScheduler: Executor lost: 5 (epoch 18)
17/06/28 15:24:55 INFO BlockManagerMasterEndpoint: Trying to remove executor 5 from BlockManagerMaster.
17/06/28 15:24:55 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(5, sd-spark06.localdomain, 46801)
17/06/28 15:24:55 INFO BlockManagerMaster: Removed 5 successfully in removeExecutor
17/06/28 15:24:55 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 5 (3/10, false)
17/06/28 15:24:55 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 5 (1/10, false)
17/06/28 15:24:55 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/5 is now EXITED (Command exited with code 52)
17/06/28 15:24:55 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/5 removed: Command exited with code 52
17/06/28 15:24:55 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 5
17/06/28 15:24:55 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/10 on worker-20170625193314-163.221.29.47-40335 (163.221.29.47:40335) with 8 cores
17/06/28 15:24:55 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/10 on hostPort 163.221.29.47:40335 with 8 cores, 1024.0 MB RAM
17/06/28 15:24:55 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/10 is now RUNNING
17/06/28 15:24:55 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:24:55 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837), which has no missing parents
17/06/28 15:24:55 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 5.6 KB, free 290.6 KB)
17/06/28 15:24:55 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.0 KB, free 293.6 KB)
17/06/28 15:24:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 163.221.29.42:44997 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:55 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
17/06/28 15:24:55 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837)
17/06/28 15:24:55 INFO TaskSchedulerImpl: Adding task set 0.3 with 7 tasks
17/06/28 15:24:55 INFO TaskSetManager: Starting task 4.0 in stage 0.3 (TID 78, sd-spark03.localdomain, partition 7,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO TaskSetManager: Starting task 0.0 in stage 0.3 (TID 79, sd-spark05.localdomain, partition 0,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO TaskSetManager: Starting task 1.0 in stage 0.3 (TID 80, sd-spark02.localdomain, partition 3,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO TaskSetManager: Starting task 5.0 in stage 0.3 (TID 81, sd-spark03.localdomain, partition 8,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO TaskSetManager: Starting task 2.0 in stage 0.3 (TID 82, sd-spark05.localdomain, partition 4,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO TaskSetManager: Starting task 3.0 in stage 0.3 (TID 83, sd-spark02.localdomain, partition 5,NODE_LOCAL, 2231 bytes)
17/06/28 15:24:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sd-spark05.localdomain:35038 (size: 3.0 KB, free: 301.1 MB)
17/06/28 15:24:55 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sd-spark02.localdomain:41630 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:55 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark02.localdomain:41630 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:24:56 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sd-spark03.localdomain:41102 (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:24:56 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark03.localdomain:41102 (size: 19.4 KB, free: 511.1 MB)
17/06/28 15:24:57 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark06.localdomain:59278) with ID 10
17/06/28 15:24:57 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark06.localdomain:40533 with 511.1 MB RAM, BlockManagerId(10, sd-spark06.localdomain, 40533)
17/06/28 15:24:58 INFO TaskSetManager: Starting task 6.0 in stage 0.3 (TID 84, sd-spark02.localdomain, partition 9,ANY, 2231 bytes)
17/06/28 15:25:03 WARN TaskSetManager: Lost task 1.2 in stage 1.2 (TID 76, sd-spark05.localdomain): FetchFailed(BlockManagerId(1, sd-spark02.localdomain, 35201), shuffleId=1, mapId=3, reduceId=2, message=
org.apache.spark.shuffle.FetchFailedException: Failed to connect to sd-spark02.localdomain/163.221.29.43:35201
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.throwFetchFailedException(ShuffleBlockFetcherIterator.scala:323)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:300)
	at org.apache.spark.storage.ShuffleBlockFetcherIterator.next(ShuffleBlockFetcherIterator.scala:51)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:371)
	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:327)
	at org.apache.spark.util.CompletionIterator.hasNext(CompletionIterator.scala:32)
	at org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:39)
	at org.apache.spark.util.collection.ExternalAppendOnlyMap.insertAll(ExternalAppendOnlyMap.scala:152)
	at org.apache.spark.Aggregator.combineValuesByKey(Aggregator.scala:45)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:89)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.IOException: Failed to connect to sd-spark02.localdomain/163.221.29.43:35201
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)
	at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)
	at org.apache.spark.network.netty.NettyBlockTransferService$$anon$1.createAndStart(NettyBlockTransferService.scala:90)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.fetchAllOutstanding(RetryingBlockFetcher.java:140)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher.access$200(RetryingBlockFetcher.java:43)
	at org.apache.spark.network.shuffle.RetryingBlockFetcher$1.run(RetryingBlockFetcher.java:170)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	... 3 more
Caused by: java.net.ConnectException: Connection refused: sd-spark02.localdomain/163.221.29.43:35201
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)
	at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)
	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)
	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)
	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)
	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)
	... 1 more

)
17/06/28 15:25:03 INFO TaskSchedulerImpl: Removed TaskSet 1.2, whose tasks have all completed, from pool 
17/06/28 15:25:03 INFO DAGScheduler: Resubmitting ShuffleMapStage 0 (mapPartitions at ALS.scala:837) and ShuffleMapStage 1 (map at ALS.scala:1080) due to fetch failure
17/06/28 15:25:03 INFO DAGScheduler: Resubmitting failed stages
17/06/28 15:25:07 INFO TaskSetManager: Finished task 2.0 in stage 0.3 (TID 82) in 11988 ms on sd-spark05.localdomain (1/7)
17/06/28 15:25:08 INFO TaskSetManager: Finished task 0.0 in stage 0.3 (TID 79) in 12163 ms on sd-spark05.localdomain (2/7)
17/06/28 15:25:08 INFO TaskSetManager: Finished task 5.0 in stage 0.3 (TID 81) in 12493 ms on sd-spark03.localdomain (3/7)
17/06/28 15:25:08 INFO TaskSetManager: Finished task 4.0 in stage 0.3 (TID 78) in 12547 ms on sd-spark03.localdomain (4/7)
17/06/28 15:25:11 INFO TaskSetManager: Finished task 1.0 in stage 0.3 (TID 80) in 15808 ms on sd-spark02.localdomain (5/7)
17/06/28 15:25:11 INFO TaskSetManager: Finished task 3.0 in stage 0.3 (TID 83) in 15837 ms on sd-spark02.localdomain (6/7)
17/06/28 15:25:13 INFO TaskSetManager: Finished task 6.0 in stage 0.3 (TID 84) in 15038 ms on sd-spark02.localdomain (7/7)
17/06/28 15:25:13 INFO TaskSchedulerImpl: Removed TaskSet 0.3, whose tasks have all completed, from pool 
17/06/28 15:25:13 INFO DAGScheduler: ShuffleMapStage 0 (mapPartitions at ALS.scala:837) finished in 18.115 s
17/06/28 15:25:13 INFO DAGScheduler: looking for newly runnable stages
17/06/28 15:25:13 INFO DAGScheduler: running: Set()
17/06/28 15:25:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
17/06/28 15:25:13 INFO DAGScheduler: failed: Set()
17/06/28 15:25:13 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080), which has no missing parents
17/06/28 15:25:13 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 6.8 KB, free 300.4 KB)
17/06/28 15:25:13 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 3.5 KB, free 303.9 KB)
17/06/28 15:25:13 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 163.221.29.42:44997 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:25:13 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
17/06/28 15:25:13 INFO DAGScheduler: Submitting 9 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080)
17/06/28 15:25:13 INFO TaskSchedulerImpl: Adding task set 1.3 with 9 tasks
17/06/28 15:25:13 INFO TaskSetManager: Starting task 0.0 in stage 1.3 (TID 85, sd-spark05.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 1.0 in stage 1.3 (TID 86, sd-spark03.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 2.0 in stage 1.3 (TID 87, sd-spark02.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 3.0 in stage 1.3 (TID 88, sd-spark05.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 4.0 in stage 1.3 (TID 89, sd-spark03.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 5.0 in stage 1.3 (TID 90, sd-spark02.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 6.0 in stage 1.3 (TID 91, sd-spark05.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 7.0 in stage 1.3 (TID 92, sd-spark02.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO TaskSetManager: Starting task 8.0 in stage 1.3 (TID 93, sd-spark05.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:13 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 163.221.29.42:44997 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sd-spark02.localdomain:41630 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark05.localdomain:35038 (size: 3.5 KB, free: 301.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark02.localdomain:41630 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sd-spark03.localdomain:41102 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sd-spark05.localdomain:35038 in memory (size: 3.0 KB, free: 301.1 MB)
17/06/28 15:25:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark02.localdomain:53548
17/06/28 15:25:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45286
17/06/28 15:25:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 209 bytes
17/06/28 15:25:14 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 209 bytes
17/06/28 15:25:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark03.localdomain:41102 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 163.221.29.42:44997 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 163.221.29.42:44997 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sd-spark04.localdomain:39985 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/28 15:25:14 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark03.localdomain:43006
17/06/28 15:25:14 INFO BlockManagerInfo: Added rdd_6_4 in memory on sd-spark05.localdomain:35038 (size: 37.9 MB, free: 263.2 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Added rdd_6_0 in memory on sd-spark05.localdomain:35038 (size: 37.8 MB, free: 225.4 MB)
17/06/28 15:25:14 INFO BlockManagerInfo: Added rdd_6_9 in memory on sd-spark05.localdomain:35038 (size: 46.9 MB, free: 178.5 MB)
17/06/28 15:25:15 INFO BlockManagerInfo: Added rdd_6_5 in memory on sd-spark03.localdomain:41102 (size: 77.9 MB, free: 433.2 MB)
17/06/28 15:25:15 INFO BlockManagerInfo: Added rdd_6_1 in memory on sd-spark03.localdomain:41102 (size: 86.2 MB, free: 346.9 MB)
17/06/28 15:25:15 INFO BlockManagerInfo: Added rdd_6_8 in memory on sd-spark02.localdomain:41630 (size: 38.8 MB, free: 472.3 MB)
17/06/28 15:25:15 INFO TaskSetManager: Finished task 3.0 in stage 1.3 (TID 88) in 1812 ms on sd-spark05.localdomain (1/9)
17/06/28 15:25:15 INFO TaskSetManager: Finished task 0.0 in stage 1.3 (TID 85) in 1846 ms on sd-spark05.localdomain (2/9)
17/06/28 15:25:15 INFO TaskSetManager: Finished task 8.0 in stage 1.3 (TID 93) in 1985 ms on sd-spark05.localdomain (3/9)
17/06/28 15:25:16 INFO TaskSetManager: Finished task 4.0 in stage 1.3 (TID 89) in 2359 ms on sd-spark03.localdomain (4/9)
17/06/28 15:25:16 INFO TaskSetManager: Finished task 1.0 in stage 1.3 (TID 86) in 2531 ms on sd-spark03.localdomain (5/9)
17/06/28 15:25:16 INFO TaskSetManager: Finished task 7.0 in stage 1.3 (TID 92) in 2619 ms on sd-spark02.localdomain (6/9)
17/06/28 15:25:16 INFO BlockManagerInfo: Added rdd_6_2 in memory on sd-spark02.localdomain:41630 (size: 126.1 MB, free: 346.2 MB)
17/06/28 15:25:17 WARN TaskSetManager: Lost task 6.0 in stage 1.3 (TID 91, sd-spark05.localdomain): java.lang.OutOfMemoryError: Java heap space
	at scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:448)
	at scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:454)
	at scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:466)
	at scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:471)
	at scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:441)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.generic.Growable$$anonfun$$plus$plus$eq$1.apply(Growable.scala:48)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:34)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:48)
	at scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:484)
	at scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:441)
	at org.apache.spark.ml.recommendation.ALS$RatingBlockBuilder.merge(ALS.scala:802)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2$$anonfun$apply$8.apply(ALS.scala:860)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2$$anonfun$apply$8.apply(ALS.scala:860)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:30)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:860)
	at org.apache.spark.ml.recommendation.ALS$$anonfun$partitionRatings$2.apply(ALS.scala:858)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$mapValues$1$$anonfun$apply$41$$anonfun$apply$42.apply(PairRDDFunctions.scala:755)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:328)
	at org.apache.spark.storage.MemoryStore.unrollSafely(MemoryStore.scala:283)
	at org.apache.spark.CacheManager.putInBlockManager(CacheManager.scala:171)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:78)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)

17/06/28 15:25:17 INFO TaskSetManager: Starting task 6.1 in stage 1.3 (TID 94, sd-spark05.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:18 ERROR TaskSchedulerImpl: Lost executor 7 on sd-spark05.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:25:18 WARN TaskSetManager: Lost task 6.1 in stage 1.3 (TID 94, sd-spark05.localdomain): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:25:18 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 0), so marking it as still running
17/06/28 15:25:18 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 4), so marking it as still running
17/06/28 15:25:18 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 9), so marking it as still running
17/06/28 15:25:18 INFO TaskSetManager: Starting task 3.1 in stage 1.3 (TID 95, sd-spark03.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:18 INFO DAGScheduler: Executor lost: 7 (epoch 22)
17/06/28 15:25:18 INFO TaskSetManager: Starting task 6.2 in stage 1.3 (TID 96, sd-spark02.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:18 INFO BlockManagerMasterEndpoint: Trying to remove executor 7 from BlockManagerMaster.
17/06/28 15:25:18 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(7, sd-spark05.localdomain, 35038)
17/06/28 15:25:18 INFO TaskSetManager: Starting task 0.1 in stage 1.3 (TID 97, sd-spark03.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:18 INFO BlockManagerMaster: Removed 7 successfully in removeExecutor
17/06/28 15:25:18 INFO TaskSetManager: Starting task 8.1 in stage 1.3 (TID 98, sd-spark02.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:18 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 7 (6/10, false)
17/06/28 15:25:18 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 7 (3/10, false)
17/06/28 15:25:18 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/7 is now EXITED (Command exited with code 52)
17/06/28 15:25:18 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/7 removed: Command exited with code 52
17/06/28 15:25:18 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 7
17/06/28 15:25:18 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/11 on worker-20170625193305-163.221.29.46-38968 (163.221.29.46:38968) with 8 cores
17/06/28 15:25:18 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/11 on hostPort 163.221.29.46:38968 with 8 cores, 1024.0 MB RAM
17/06/28 15:25:18 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/11 is now RUNNING
17/06/28 15:25:19 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark05.localdomain:45332) with ID 11
17/06/28 15:25:20 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark05.localdomain:41593 with 511.1 MB RAM, BlockManagerId(11, sd-spark05.localdomain, 41593)
17/06/28 15:25:21 INFO TaskSetManager: Finished task 2.0 in stage 1.3 (TID 87) in 7861 ms on sd-spark02.localdomain (4/9)
17/06/28 15:25:23 INFO TaskSetManager: Lost task 5.0 in stage 1.3 (TID 90) on executor sd-spark02.localdomain: java.lang.OutOfMemoryError (Java heap space) [duplicate 1]
17/06/28 15:25:23 INFO TaskSetManager: Starting task 5.1 in stage 1.3 (TID 99, sd-spark03.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:24 ERROR TaskSchedulerImpl: Lost executor 9 on sd-spark02.localdomain: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:25:24 WARN TaskSetManager: Lost task 8.1 in stage 1.3 (TID 98, sd-spark02.localdomain): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:25:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 8), so marking it as still running
17/06/28 15:25:24 WARN TaskSetManager: Lost task 6.2 in stage 1.3 (TID 96, sd-spark02.localdomain): ExecutorLostFailure (executor 9 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
17/06/28 15:25:24 INFO DAGScheduler: Resubmitted ShuffleMapTask(1, 2), so marking it as still running
17/06/28 15:25:24 INFO TaskSetManager: Starting task 2.1 in stage 1.3 (TID 100, sd-spark03.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:24 INFO DAGScheduler: Executor lost: 9 (epoch 24)
17/06/28 15:25:24 INFO TaskSetManager: Starting task 6.3 in stage 1.3 (TID 101, sd-spark05.localdomain, partition 7,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:24 INFO BlockManagerMasterEndpoint: Trying to remove executor 9 from BlockManagerMaster.
17/06/28 15:25:24 INFO BlockManagerMasterEndpoint: Removing block manager BlockManagerId(9, sd-spark02.localdomain, 41630)
17/06/28 15:25:24 INFO TaskSetManager: Starting task 8.2 in stage 1.3 (TID 102, sd-spark05.localdomain, partition 9,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:24 INFO BlockManagerMaster: Removed 9 successfully in removeExecutor
17/06/28 15:25:24 INFO TaskSetManager: Starting task 7.1 in stage 1.3 (TID 103, sd-spark05.localdomain, partition 8,NODE_LOCAL, 1949 bytes)
17/06/28 15:25:24 INFO ShuffleMapStage: ShuffleMapStage 0 is now unavailable on executor 9 (3/10, false)
17/06/28 15:25:24 INFO ShuffleMapStage: ShuffleMapStage 1 is now unavailable on executor 9 (2/10, false)
17/06/28 15:25:24 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/9 is now EXITED (Command exited with code 52)
17/06/28 15:25:24 INFO SparkDeploySchedulerBackend: Executor app-20170628152338-0001/9 removed: Command exited with code 52
17/06/28 15:25:24 INFO SparkDeploySchedulerBackend: Asked to remove non-existent executor 9
17/06/28 15:25:24 INFO AppClient$ClientEndpoint: Executor added: app-20170628152338-0001/12 on worker-20170625193237-163.221.29.43-45839 (163.221.29.43:45839) with 8 cores
17/06/28 15:25:24 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170628152338-0001/12 on hostPort 163.221.29.43:45839 with 8 cores, 1024.0 MB RAM
17/06/28 15:25:24 INFO AppClient$ClientEndpoint: Executor updated: app-20170628152338-0001/12 is now RUNNING
17/06/28 15:25:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark05.localdomain:41593 (size: 3.5 KB, free: 511.1 MB)
17/06/28 15:25:24 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark05.localdomain:45332
17/06/28 15:25:24 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 184 bytes
17/06/28 15:25:24 WARN TaskSetManager: Lost task 6.3 in stage 1.3 (TID 101, sd-spark05.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=7, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:25:24 INFO DAGScheduler: Marking ShuffleMapStage 1 (map at ALS.scala:1080) as failed due to a fetch failure from ShuffleMapStage 0 (mapPartitions at ALS.scala:837)
17/06/28 15:25:24 INFO DAGScheduler: ShuffleMapStage 1 (map at ALS.scala:1080) failed in 10.484 s
17/06/28 15:25:24 WARN TaskSetManager: Lost task 7.1 in stage 1.3 (TID 103, sd-spark05.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=8, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:25:24 WARN TaskSetManager: Lost task 8.2 in stage 1.3 (TID 102, sd-spark05.localdomain): FetchFailed(null, shuffleId=1, mapId=-1, reduceId=9, message=
org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

)
17/06/28 15:25:24 INFO DAGScheduler: Job 0 failed: count at ALS.scala:596, took 105.368302 s
Exception in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: ShuffleMapStage 1 (map at ALS.scala:1080) has failed the maximum allowable number of times: 4. Most recent failure reason: org.apache.spark.shuffle.MetadataFetchFailedException: Missing an output location for shuffle 1
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:542)
	at org.apache.spark.MapOutputTracker$$anonfun$org$apache$spark$MapOutputTracker$$convertMapStatuses$2.apply(MapOutputTracker.scala:538)
	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:772)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108)
	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:771)
	at org.apache.spark.MapOutputTracker$.org$apache$spark$MapOutputTracker$$convertMapStatuses(MapOutputTracker.scala:538)
	at org.apache.spark.MapOutputTracker.getMapSizesByExecutorId(MapOutputTracker.scala:155)
	at org.apache.spark.shuffle.BlockStoreShuffleReader.read(BlockStoreShuffleReader.scala:47)
	at org.apache.spark.rdd.ShuffledRDD.compute(ShuffledRDD.scala:98)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:213)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:748)

	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1258)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1637)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1599)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1588)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1143)
	at org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:596)
	at org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:239)
	at org.apache.spark.mllib.recommendation.ALS$.train(ALS.scala:328)
	at org.apache.spark.mllib.recommendation.ALS$.train(ALS.scala:346)
	at S90_000_000_T$.main(S90_000_000_T.scala:14)
	at S90_000_000_T.main(S90_000_000_T.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/06/28 15:25:24 INFO SparkContext: Invoking stop() from shutdown hook
17/06/28 15:25:24 INFO SparkUI: Stopped Spark web UI at http://163.221.29.42:4040
17/06/28 15:25:24 INFO SparkDeploySchedulerBackend: Shutting down all executors
17/06/28 15:25:24 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
17/06/28 15:25:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/06/28 15:25:24 INFO MemoryStore: MemoryStore cleared
17/06/28 15:25:24 INFO BlockManager: BlockManager stopped
17/06/28 15:25:24 INFO BlockManagerMaster: BlockManagerMaster stopped
17/06/28 15:25:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/06/28 15:25:24 INFO SparkContext: Successfully stopped SparkContext
17/06/28 15:25:24 INFO ShutdownHookManager: Shutdown hook called
17/06/28 15:25:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-b50314b6-138a-4be6-800d-cd1ac1417b28/httpd-36850bb1-00e1-46a4-98a9-44ca584f1dfa
17/06/28 15:25:24 INFO ShutdownHookManager: Deleting directory /tmp/spark-b50314b6-138a-4be6-800d-cd1ac1417b28
17/06/28 15:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/06/28 15:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/06/28 15:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.

real	1m48.865s
user	0m14.651s
sys	0m0.897s
