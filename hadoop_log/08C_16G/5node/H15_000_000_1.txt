17/06/28 13:36:48 INFO common.AbstractJob: Command line arguments: {--alpha=[40], --endPhase=[2147483647], --implicitFeedback=[false], --input=[hdfs://sd-spark01.localdomain:9000/data/output_data_naist_tsv/15000000.tsv], --lambda=[0.01], --numFeatures=[100], --numIterations=[30], --numThreadsPerSolver=[1], --output=[hdfs://sd-spark01.localdomain:9000/H15_000_000], --startPhase=[0], --tempDir=[hdfs://sd-spark01.localdomain:9000/tmp1]}
17/06/28 13:36:49 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/06/28 13:36:49 INFO Configuration.deprecation: mapred.input.dir is deprecated. Instead, use mapreduce.input.fileinputformat.inputdir
17/06/28 13:36:49 INFO Configuration.deprecation: mapred.compress.map.output is deprecated. Instead, use mapreduce.map.output.compress
17/06/28 13:36:49 INFO Configuration.deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
17/06/28 13:36:49 INFO client.RMProxy: Connecting to ResourceManager at sd-spark01.localdomain/163.221.29.42:8032
17/06/28 13:36:51 INFO input.FileInputFormat: Total input paths to process : 1
17/06/28 13:36:51 INFO mapreduce.JobSubmitter: number of splits:2
17/06/28 13:36:51 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1498286170644_0100
17/06/28 13:36:51 INFO impl.YarnClientImpl: Submitted application application_1498286170644_0100
17/06/28 13:36:51 INFO mapreduce.Job: The url to track the job: http://sd-spark01.localdomain:8088/proxy/application_1498286170644_0100/
17/06/28 13:36:51 INFO mapreduce.Job: Running job: job_1498286170644_0100
17/06/28 13:36:57 INFO mapreduce.Job: Job job_1498286170644_0100 running in uber mode : false
17/06/28 13:36:57 INFO mapreduce.Job:  map 0% reduce 0%
17/06/28 13:37:06 INFO mapreduce.Job:  map 28% reduce 0%
17/06/28 13:37:09 INFO mapreduce.Job:  map 29% reduce 0%
17/06/28 13:37:12 INFO mapreduce.Job:  map 49% reduce 0%
17/06/28 13:37:15 INFO mapreduce.Job:  map 51% reduce 0%
17/06/28 13:37:18 INFO mapreduce.Job:  map 60% reduce 0%
17/06/28 13:37:21 INFO mapreduce.Job:  map 80% reduce 0%
17/06/28 13:37:24 INFO mapreduce.Job:  map 82% reduce 0%
17/06/28 13:37:27 INFO mapreduce.Job:  map 84% reduce 0%
17/06/28 13:37:30 INFO mapreduce.Job:  map 100% reduce 0%
17/06/28 13:37:34 INFO mapreduce.Job:  map 100% reduce 69%
17/06/28 13:37:37 INFO mapreduce.Job:  map 100% reduce 87%
17/06/28 13:37:40 INFO mapreduce.Job:  map 100% reduce 100%
17/06/28 13:37:41 INFO mapreduce.Job: Job job_1498286170644_0100 completed successfully
17/06/28 13:37:41 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=123058662
		FILE: Number of bytes written=184429157
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=224711625
		HDFS: Number of bytes written=146605131
		HDFS: Number of read operations=9
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=2
		Launched reduce tasks=1
		Data-local map tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=60067
		Total time spent by all reduces in occupied slots (ms)=14203
		Total time spent by all map tasks (ms)=60067
		Total time spent by all reduce tasks (ms)=14203
		Total vcore-milliseconds taken by all map tasks=60067
		Total vcore-milliseconds taken by all reduce tasks=14203
		Total megabyte-milliseconds taken by all map tasks=61508608
		Total megabyte-milliseconds taken by all reduce tasks=14543872
	Map-Reduce Framework
		Map input records=15000000
		Map output records=15000000
		Map output bytes=273023741
		Map output materialized bytes=61043676
		Input split bytes=278
		Combine input records=15121048
		Combine output records=156569
		Reduce input groups=17768
		Reduce shuffle bytes=61043676
		Reduce input records=35521
		Reduce output records=17768
		Spilled Records=192090
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=1831
		CPU time spent (ms)=81280
		Physical memory (bytes) snapshot=785391616
		Virtual memory (bytes) snapshot=6410801152
		Total committed heap usage (bytes)=568328192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=224711347
	File Output Format Counters 
		Bytes Written=146605131
17/06/28 13:37:41 INFO client.RMProxy: Connecting to ResourceManager at sd-spark01.localdomain/163.221.29.42:8032
17/06/28 13:37:41 INFO input.FileInputFormat: Total input paths to process : 1
17/06/28 13:37:41 INFO mapreduce.JobSubmitter: number of splits:1
17/06/28 13:37:41 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1498286170644_0101
17/06/28 13:37:41 INFO impl.YarnClientImpl: Submitted application application_1498286170644_0101
17/06/28 13:37:41 INFO mapreduce.Job: The url to track the job: http://sd-spark01.localdomain:8088/proxy/application_1498286170644_0101/
17/06/28 13:37:41 INFO mapreduce.Job: Running job: job_1498286170644_0101
17/06/28 13:37:45 INFO mapreduce.Job: Job job_1498286170644_0101 running in uber mode : false
17/06/28 13:37:45 INFO mapreduce.Job:  map 0% reduce 0%
17/06/28 13:37:56 INFO mapreduce.Job:  map 13% reduce 0%
17/06/28 13:37:59 INFO mapreduce.Job:  map 23% reduce 0%
17/06/28 13:38:02 INFO mapreduce.Job:  map 26% reduce 0%
17/06/28 13:38:05 INFO mapreduce.Job:  map 33% reduce 0%
17/06/28 13:38:08 INFO mapreduce.Job:  map 41% reduce 0%
17/06/28 13:38:11 INFO mapreduce.Job:  map 43% reduce 0%
17/06/28 13:38:14 INFO mapreduce.Job:  map 53% reduce 0%
17/06/28 13:38:20 INFO mapreduce.Job:  map 63% reduce 0%
17/06/28 13:38:26 INFO mapreduce.Job:  map 67% reduce 0%
17/06/28 13:38:29 INFO mapreduce.Job:  map 91% reduce 0%
17/06/28 13:38:32 INFO mapreduce.Job:  map 100% reduce 0%
17/06/28 13:38:48 INFO mapreduce.Job:  map 100% reduce 97%
17/06/28 13:38:49 INFO mapreduce.Job:  map 100% reduce 100%
17/06/28 13:38:49 INFO mapreduce.Job: Job job_1498286170644_0101 completed successfully
17/06/28 13:38:49 INFO mapreduce.Job: Counters: 50
	File System Counters
		FILE: Number of bytes read=97727650
		FILE: Number of bytes written=144634588
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146605260
		HDFS: Number of bytes written=153968988
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=49266
		Total time spent by all reduces in occupied slots (ms)=8443
		Total time spent by all map tasks (ms)=49266
		Total time spent by all reduce tasks (ms)=8443
		Total vcore-milliseconds taken by all map tasks=49266
		Total vcore-milliseconds taken by all reduce tasks=8443
		Total megabyte-milliseconds taken by all map tasks=50448384
		Total megabyte-milliseconds taken by all reduce tasks=8645632
	Map-Reduce Framework
		Map input records=17768
		Map output records=15000000
		Map output bytes=316139296
		Map output materialized bytes=46689551
		Input split bytes=129
		Combine input records=17542420
		Combine output records=3010438
		Reduce input groups=468018
		Reduce shuffle bytes=46689551
		Reduce input records=468018
		Reduce output records=468018
		Spilled Records=3478456
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=1093
		CPU time spent (ms)=67360
		Physical memory (bytes) snapshot=502321152
		Virtual memory (bytes) snapshot=4311560192
		Total committed heap usage (bytes)=358088704
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146605131
	File Output Format Counters 
		Bytes Written=153968988
	org.apache.mahout.cf.taste.hadoop.als.ParallelALSFactorizationJob$Stats
		NUM_USERS=468018
17/06/28 13:38:49 INFO client.RMProxy: Connecting to ResourceManager at sd-spark01.localdomain/163.221.29.42:8032
17/06/28 13:38:49 INFO input.FileInputFormat: Total input paths to process : 1
17/06/28 13:38:49 INFO mapreduce.JobSubmitter: number of splits:1
17/06/28 13:38:49 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1498286170644_0102
17/06/28 13:38:49 INFO impl.YarnClientImpl: Submitted application application_1498286170644_0102
17/06/28 13:38:49 INFO mapreduce.Job: The url to track the job: http://sd-spark01.localdomain:8088/proxy/application_1498286170644_0102/
17/06/28 13:38:49 INFO mapreduce.Job: Running job: job_1498286170644_0102
17/06/28 13:38:56 INFO mapreduce.Job: Job job_1498286170644_0102 running in uber mode : false
17/06/28 13:38:56 INFO mapreduce.Job:  map 0% reduce 0%
17/06/28 13:39:01 INFO mapreduce.Job:  map 100% reduce 0%
17/06/28 13:39:06 INFO mapreduce.Job:  map 100% reduce 100%
17/06/28 13:39:06 INFO mapreduce.Job: Job job_1498286170644_0102 completed successfully
17/06/28 13:39:06 INFO mapreduce.Job: Counters: 49
	File System Counters
		FILE: Number of bytes read=132550
		FILE: Number of bytes written=482479
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=146605260
		HDFS: Number of bytes written=160030
		HDFS: Number of read operations=7
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
	Job Counters 
		Launched map tasks=1
		Launched reduce tasks=1
		Rack-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=3804
		Total time spent by all reduces in occupied slots (ms)=1941
		Total time spent by all map tasks (ms)=3804
		Total time spent by all reduce tasks (ms)=1941
		Total vcore-milliseconds taken by all map tasks=3804
		Total vcore-milliseconds taken by all reduce tasks=1941
		Total megabyte-milliseconds taken by all map tasks=3895296
		Total megabyte-milliseconds taken by all reduce tasks=1987584
	Map-Reduce Framework
		Map input records=17768
		Map output records=17768
		Map output bytes=374388
		Map output materialized bytes=132542
		Input split bytes=129
		Combine input records=17768
		Combine output records=1
		Reduce input groups=1
		Reduce shuffle bytes=132542
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=139
		CPU time spent (ms)=4200
		Physical memory (bytes) snapshot=462086144
		Virtual memory (bytes) snapshot=4273815552
		Total committed heap usage (bytes)=343408640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146605131
	File Output Format Counters 
		Bytes Written=160030
17/06/28 13:39:07 INFO ipc.Client: Retrying connect to server: sd-spark04.localdomain/163.221.29.45:44232. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:08 INFO ipc.Client: Retrying connect to server: sd-spark04.localdomain/163.221.29.45:44232. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:09 INFO ipc.Client: Retrying connect to server: sd-spark04.localdomain/163.221.29.45:44232. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=3, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:10 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
17/06/28 13:39:11 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:12 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:13 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:14 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:15 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:16 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:17 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:18 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:19 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:20 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:20 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
17/06/28 13:39:21 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:22 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:23 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:24 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:25 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:26 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:27 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:28 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:29 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:30 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:30 INFO mapred.ClientServiceDelegate: Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server
17/06/28 13:39:31 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:32 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:33 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:34 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:35 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:36 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:37 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:38 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:39 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
17/06/28 13:39:40 INFO ipc.Client: Retrying connect to server: sd-spark01.localdomain/163.221.29.42:10020. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
Exception in thread "main" java.io.IOException: java.net.ConnectException: Call From sd-spark01.localdomain/163.221.29.42 to sd-spark01.localdomain:10020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:338)
	at org.apache.hadoop.mapred.ClientServiceDelegate.getJobCounters(ClientServiceDelegate.java:375)
	at org.apache.hadoop.mapred.YARNRunner.getJobCounters(YARNRunner.java:565)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:768)
	at org.apache.hadoop.mapreduce.Job$7.run(Job.java:765)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1692)
	at org.apache.hadoop.mapreduce.Job.getCounters(Job.java:765)
	at org.apache.mahout.cf.taste.hadoop.als.ParallelALSFactorizationJob.run(ParallelALSFactorizationJob.java:195)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:84)
	at org.apache.mahout.cf.taste.hadoop.als.ParallelALSFactorizationJob.main(ParallelALSFactorizationJob.java:108)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.util.RunJar.run(RunJar.java:221)
	at org.apache.hadoop.util.RunJar.main(RunJar.java:136)
Caused by: java.net.ConnectException: Call From sd-spark01.localdomain/163.221.29.42 to sd-spark01.localdomain:10020 failed on connection exception: java.net.ConnectException: Connection refused; For more details see:  http://wiki.apache.org/hadoop/ConnectionRefused
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:791)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:731)
	at org.apache.hadoop.ipc.Client.call(Client.java:1474)
	at org.apache.hadoop.ipc.Client.call(Client.java:1401)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)
	at com.sun.proxy.$Proxy14.getCounters(Unknown Source)
	at org.apache.hadoop.mapreduce.v2.api.impl.pb.client.MRClientProtocolPBClientImpl.getCounters(MRClientProtocolPBClientImpl.java:166)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.mapred.ClientServiceDelegate.invoke(ClientServiceDelegate.java:324)
	... 18 more
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:530)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:494)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:609)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:707)
	at org.apache.hadoop.ipc.Client$Connection.access$2800(Client.java:370)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1523)
	at org.apache.hadoop.ipc.Client.call(Client.java:1440)
	... 27 more

real	2m57.272s
user	0m11.787s
sys	0m3.583s
