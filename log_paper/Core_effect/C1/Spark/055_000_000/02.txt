Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/06/30 04:33:57 INFO SparkContext: Running Spark version 1.6.0
17/06/30 04:33:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/06/30 04:33:58 INFO SecurityManager: Changing view acls to: hadoop
17/06/30 04:33:58 INFO SecurityManager: Changing modify acls to: hadoop
17/06/30 04:33:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)
17/06/30 04:33:58 INFO Utils: Successfully started service 'sparkDriver' on port 37602.
17/06/30 04:33:59 INFO Slf4jLogger: Slf4jLogger started
17/06/30 04:33:59 INFO Remoting: Starting remoting
17/06/30 04:33:59 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 41262.
17/06/30 04:33:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@163.221.29.42:41262]
17/06/30 04:33:59 INFO SparkEnv: Registering MapOutputTracker
17/06/30 04:33:59 INFO SparkEnv: Registering BlockManagerMaster
17/06/30 04:33:59 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-144d6cec-a298-4f1e-a765-64ed577edc20
17/06/30 04:33:59 INFO MemoryStore: MemoryStore started with capacity 511.1 MB
17/06/30 04:33:59 INFO SparkEnv: Registering OutputCommitCoordinator
17/06/30 04:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/06/30 04:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
17/06/30 04:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
17/06/30 04:34:00 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
17/06/30 04:34:01 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
17/06/30 04:34:01 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
17/06/30 04:34:01 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.
17/06/30 04:34:01 WARN QueuedThreadPool: 5 threads could not be stopped
17/06/30 04:34:01 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.
17/06/30 04:34:01 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.
17/06/30 04:34:02 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.
17/06/30 04:34:02 INFO Utils: Successfully started service 'SparkUI' on port 4050.
17/06/30 04:34:02 INFO SparkUI: Started SparkUI at http://163.221.29.42:4050
17/06/30 04:34:02 INFO HttpFileServer: HTTP File server directory is /tmp/spark-2bcef316-5eac-48e1-bb65-5da882d4d127/httpd-810a3b77-dd7e-4889-8d7b-8919bf2c5057
17/06/30 04:34:02 INFO HttpServer: Starting HTTP Server
17/06/30 04:34:02 INFO Utils: Successfully started service 'HTTP file server' on port 34114.
17/06/30 04:34:02 INFO SparkContext: Added JAR file:/home/hadoop/Sparksubmit/target/scala-2.10/spark-naist_2.10-1.0.jar at http://163.221.29.42:34114/jars/spark-naist_2.10-1.0.jar with timestamp 1498764842417
17/06/30 04:34:02 INFO AppClient$ClientEndpoint: Connecting to master spark://sd-spark01.localdomain:7077...
17/06/30 04:34:02 INFO SparkDeploySchedulerBackend: Connected to Spark cluster with app ID app-20170630043402-0091
17/06/30 04:34:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45435.
17/06/30 04:34:02 INFO NettyBlockTransferService: Server created on 45435
17/06/30 04:34:02 INFO BlockManagerMaster: Trying to register BlockManager
17/06/30 04:34:02 INFO BlockManagerMasterEndpoint: Registering block manager 163.221.29.42:45435 with 511.1 MB RAM, BlockManagerId(driver, 163.221.29.42, 45435)
17/06/30 04:34:02 INFO BlockManagerMaster: Registered BlockManager
17/06/30 04:34:03 INFO EventLoggingListener: Logging events to hdfs://sd-spark01.localdomain:9000/Log/app-20170630043402-0091
17/06/30 04:34:03 INFO SparkDeploySchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
17/06/30 04:34:04 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 208.8 KB, free 208.8 KB)
17/06/30 04:34:04 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 19.4 KB, free 228.2 KB)
17/06/30 04:34:04 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 163.221.29.42:45435 (size: 19.4 KB, free: 511.1 MB)
17/06/30 04:34:04 INFO SparkContext: Created broadcast 0 from textFile at S55_000_000_T.scala:10
17/06/30 04:34:04 INFO FileInputFormat: Total input paths to process : 1
17/06/30 04:34:04 INFO SparkContext: Starting job: count at ALS.scala:596
17/06/30 04:34:04 INFO DAGScheduler: Registering RDD 4 (mapPartitions at ALS.scala:837)
17/06/30 04:34:04 INFO DAGScheduler: Registering RDD 7 (map at ALS.scala:1080)
17/06/30 04:34:04 INFO DAGScheduler: Got job 0 (count at ALS.scala:596) with 3 output partitions
17/06/30 04:34:04 INFO DAGScheduler: Final stage: ResultStage 2 (count at ALS.scala:596)
17/06/30 04:34:04 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/06/30 04:34:04 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/06/30 04:34:04 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837), which has no missing parents
17/06/30 04:34:04 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 233.8 KB)
17/06/30 04:34:04 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.0 KB, free 236.9 KB)
17/06/30 04:34:04 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 163.221.29.42:45435 (size: 3.0 KB, free: 511.1 MB)
17/06/30 04:34:04 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1006
17/06/30 04:34:04 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at mapPartitions at ALS.scala:837)
17/06/30 04:34:04 INFO TaskSchedulerImpl: Adding task set 0.0 with 7 tasks
17/06/30 04:34:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:34:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:34:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:35:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:35:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:35:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:35:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:36:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:36:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:36:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:36:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:37:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:37:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:37:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:37:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:38:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:38:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:38:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:38:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:39:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:39:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:39:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:39:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:40:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:40:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:40:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:40:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:41:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:41:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:41:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:41:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:42:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:42:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:42:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:42:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:43:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:43:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:43:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:43:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:44:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:44:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:44:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:44:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:45:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:45:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:45:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:45:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:46:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:46:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:46:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:46:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:47:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:47:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:47:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:47:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:48:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:48:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:48:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:48:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:49:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:49:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:49:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:49:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:50:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:50:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:50:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:50:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:51:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:51:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:51:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:51:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:52:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:52:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:52:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:52:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:53:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:53:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:53:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:53:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:54:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:54:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:54:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:54:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:55:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:55:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:55:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:55:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:56:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:56:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:56:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:56:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:57:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:57:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:57:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:57:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:58:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:58:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:58:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:58:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:59:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:59:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:59:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 04:59:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:00:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:00:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:00:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:00:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:01:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:01:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:01:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:01:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:02:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:02:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:02:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:02:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:03:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:03:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:03:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:03:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:04:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:04:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:04:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:04:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:05:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:05:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:05:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:05:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:06:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:06:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:06:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:06:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:07:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:07:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:07:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:07:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:08:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:08:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:08:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:08:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:09:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:09:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:09:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:09:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:10:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:10:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:10:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:10:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:11:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:11:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:11:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:11:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:12:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:12:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:12:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:12:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:13:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:13:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:13:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:13:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:14:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:14:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:14:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:14:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:15:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:15:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:15:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:15:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:16:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:16:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:16:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:16:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:17:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:17:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:17:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:17:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:18:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:18:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:18:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:18:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:19:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:19:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:19:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:19:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:20:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:20:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:20:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:20:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:21:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:21:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:21:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:21:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:22:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:22:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:22:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:22:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:23:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:23:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:23:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:23:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:24:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:24:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:24:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:24:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:25:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:25:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:25:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:25:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:26:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:26:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:26:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:26:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:27:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:27:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:27:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:27:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:28:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:28:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:28:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:28:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:29:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:29:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:29:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:29:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:30:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:30:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:30:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:30:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:31:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:31:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:31:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:31:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:32:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:32:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:32:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:32:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:33:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:33:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:33:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:33:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:34:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:34:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:34:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:34:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:35:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:35:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:35:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:35:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:36:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:36:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:36:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:36:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:37:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:37:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:37:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:37:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:38:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:38:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:38:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:38:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:39:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:39:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:39:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:39:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:40:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:40:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:40:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:40:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:41:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:41:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:41:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:41:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:42:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:42:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:42:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:42:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:43:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:43:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:43:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:43:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:44:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:44:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:44:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:44:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:45:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:45:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:45:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:45:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:46:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:46:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:46:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:46:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:47:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:47:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:47:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:47:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:48:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:48:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:48:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:48:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:49:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:49:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:49:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:49:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:50:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:50:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:50:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:50:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:51:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:51:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:51:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:51:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:52:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:52:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:52:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:52:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:53:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:53:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:53:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:53:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:54:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:54:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:54:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:54:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:55:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:55:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:55:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:55:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:56:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:56:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:56:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:56:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:57:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:57:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:57:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:57:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:58:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:58:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:58:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:58:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:59:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:59:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:59:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 05:59:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:00:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:00:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:00:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:00:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:01:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:01:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:01:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:01:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:02:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:02:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:02:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:02:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:03:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:03:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:03:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:03:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:04:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:04:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:04:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:04:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:05:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:05:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:05:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:05:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:06:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:06:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:06:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:06:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:07:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:07:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:07:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:07:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:08:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:08:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:08:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:08:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:09:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:09:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:09:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:09:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:10:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:10:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:10:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:10:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:11:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:11:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:11:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:11:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:12:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:12:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:12:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:12:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:13:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:13:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:13:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:13:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:14:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:14:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:14:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:14:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:15:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:15:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:15:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:15:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:16:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:16:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:16:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:16:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:17:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:17:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:17:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:17:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:18:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:18:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:18:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:18:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:19:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:19:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:19:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:19:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:20:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:20:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:20:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:20:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:21:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:21:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:21:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:21:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:22:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:22:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:22:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:22:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:23:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:23:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:23:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:23:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:24:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:24:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:24:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:24:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:25:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:25:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:25:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:25:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:26:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:26:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:26:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:26:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:27:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:27:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:27:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:27:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:28:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:28:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:28:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:28:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:29:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:29:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:29:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:29:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:30:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:30:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:30:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:30:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:31:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:31:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:31:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:31:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:32:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:32:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:32:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:32:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:33:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:33:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:33:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:33:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:34:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:34:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:34:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:34:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:35:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:35:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:35:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:35:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:36:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:36:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:36:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:36:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:37:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:37:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:37:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:37:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:38:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:38:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:38:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:38:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:39:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:39:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:39:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:39:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:40:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:40:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:40:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:40:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:41:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:41:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:41:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:41:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:42:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:42:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:42:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:42:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:43:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:43:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:43:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:43:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:44:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:44:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:44:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:44:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:45:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:45:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:45:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:45:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:46:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:46:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:46:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:46:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:47:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:47:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:47:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:47:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:48:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:48:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:48:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:48:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:49:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:49:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:49:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:49:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:50:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:50:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:50:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:50:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:51:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:51:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:51:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:51:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:52:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:52:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:52:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:52:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:53:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:53:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:53:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:53:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:54:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:54:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:54:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:54:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:55:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:55:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:55:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:55:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:56:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:56:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:56:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:56:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:57:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:57:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:57:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:57:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:58:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:58:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:58:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:58:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:59:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:59:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:59:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 06:59:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:00:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:00:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:00:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:00:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:01:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:01:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:01:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:01:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:02:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:02:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:02:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:02:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:03:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:03:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:03:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:03:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:04:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:04:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:04:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:04:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:05:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:05:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:05:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:05:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:06:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:06:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:06:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:06:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:07:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:07:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:07:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:07:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:08:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:08:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:08:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:08:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:09:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:09:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:09:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:09:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:10:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:10:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:10:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:10:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:11:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:11:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:11:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:11:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:12:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:12:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:12:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:12:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:13:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:13:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:13:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:13:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:14:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:14:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:14:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:14:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:15:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:15:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:15:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:15:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:16:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:16:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:16:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:16:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:17:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:17:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:17:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:17:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:18:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:18:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:18:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:18:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:19:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:19:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:19:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:19:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:20:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:20:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:20:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:20:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:21:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:21:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:21:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:21:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:22:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:22:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:22:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:22:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:23:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:23:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:23:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:23:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:24:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:24:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:24:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:24:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:25:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:25:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:25:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:25:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:26:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:26:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:26:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:26:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:27:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:27:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:27:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:27:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:28:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:28:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:28:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:28:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:29:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:29:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:29:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:29:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:30:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:30:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:30:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:30:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:31:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:31:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:31:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:31:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:32:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:32:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:32:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:32:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:33:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:33:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:33:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:33:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:34:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:34:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:34:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:34:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:35:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:35:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:35:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:35:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:36:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:36:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:36:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:36:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:37:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:37:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:37:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:37:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:38:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:38:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:38:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:38:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:39:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:39:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:39:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:39:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:40:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:40:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:40:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:40:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:41:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:41:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:41:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:41:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:42:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:42:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:42:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:42:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:43:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:43:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:43:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:43:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:44:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:44:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:44:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:44:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:45:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:45:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:45:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:45:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:46:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:46:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:46:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:46:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:47:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:47:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:47:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:47:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:48:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:48:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:48:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:48:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:49:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:49:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:49:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:49:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:50:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:50:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:50:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:50:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:51:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:51:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:51:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:51:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:52:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:52:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:52:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:52:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:53:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:53:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:53:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:53:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:54:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:54:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:54:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:54:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:55:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:55:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:55:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:55:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:56:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:56:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:56:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:56:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:57:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:57:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:57:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:57:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:58:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:58:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:58:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:58:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:59:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:59:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:59:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 07:59:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:00:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:00:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:00:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:00:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:01:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:01:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:01:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:01:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:02:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:02:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:02:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:02:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:03:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:03:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:03:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:03:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:04:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:04:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:04:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:04:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:05:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:05:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:05:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:05:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:06:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:06:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:06:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:06:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:07:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:07:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:07:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:07:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:08:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:08:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:08:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:08:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:09:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:09:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:09:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:09:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:10:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:10:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:10:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:10:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:11:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:11:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:11:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:11:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:12:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:12:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:12:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:12:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:13:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:13:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:13:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:13:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:14:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:14:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:14:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:14:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:15:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:15:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:15:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:15:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:16:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:16:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:16:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:16:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:17:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:17:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:17:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:17:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:18:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:18:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:18:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:18:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:19:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:19:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:19:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:19:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:20:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:20:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:20:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:20:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:21:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:21:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:21:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:21:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:22:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:22:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:22:34 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:22:49 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:23:04 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:23:19 WARN TaskSchedulerImpl: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor added: app-20170630043402-0091/0 on worker-20170629154100-163.221.29.47-37090 (163.221.29.47:37090) with 2 cores
17/06/30 08:23:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170630043402-0091/0 on hostPort 163.221.29.47:37090 with 2 cores, 8.0 GB RAM
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor added: app-20170630043402-0091/1 on worker-20170629154027-163.221.29.43-34661 (163.221.29.43:34661) with 2 cores
17/06/30 08:23:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170630043402-0091/1 on hostPort 163.221.29.43:34661 with 2 cores, 8.0 GB RAM
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor added: app-20170630043402-0091/2 on worker-20170629154054-163.221.29.46-38493 (163.221.29.46:38493) with 2 cores
17/06/30 08:23:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170630043402-0091/2 on hostPort 163.221.29.46:38493 with 2 cores, 8.0 GB RAM
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor added: app-20170630043402-0091/3 on worker-20170629154046-163.221.29.45-33876 (163.221.29.45:33876) with 2 cores
17/06/30 08:23:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170630043402-0091/3 on hostPort 163.221.29.45:33876 with 2 cores, 8.0 GB RAM
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor added: app-20170630043402-0091/4 on worker-20170629154036-163.221.29.44-42805 (163.221.29.44:42805) with 2 cores
17/06/30 08:23:25 INFO SparkDeploySchedulerBackend: Granted executor ID app-20170630043402-0091/4 on hostPort 163.221.29.44:42805 with 2 cores, 8.0 GB RAM
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor updated: app-20170630043402-0091/0 is now RUNNING
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor updated: app-20170630043402-0091/1 is now RUNNING
17/06/30 08:23:25 INFO AppClient$ClientEndpoint: Executor updated: app-20170630043402-0091/3 is now RUNNING
17/06/30 08:23:27 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark04.localdomain:40512) with ID 3
17/06/30 08:23:27 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark04.localdomain:42799 with 5.5 GB RAM, BlockManagerId(3, sd-spark04.localdomain, 42799)
17/06/30 08:23:27 INFO AppClient$ClientEndpoint: Executor updated: app-20170630043402-0091/2 is now RUNNING
17/06/30 08:23:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 0, sd-spark04.localdomain, partition 1,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:27 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark02.localdomain:42198) with ID 1
17/06/30 08:23:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 1, sd-spark02.localdomain, partition 0,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, sd-spark02.localdomain, partition 2,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:27 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark06.localdomain:52898) with ID 0
17/06/30 08:23:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, sd-spark06.localdomain, partition 3,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:27 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 4, sd-spark06.localdomain, partition 6,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:28 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark02.localdomain:36253 with 5.5 GB RAM, BlockManagerId(1, sd-spark02.localdomain, 36253)
17/06/30 08:23:28 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark06.localdomain:42959 with 5.5 GB RAM, BlockManagerId(0, sd-spark06.localdomain, 42959)
17/06/30 08:23:28 INFO AppClient$ClientEndpoint: Executor updated: app-20170630043402-0091/4 is now RUNNING
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark06.localdomain:42959 (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark04.localdomain:42799 (size: 19.4 KB, free: 5.5 GB)
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark06.localdomain:42959 (size: 19.4 KB, free: 5.5 GB)
17/06/30 08:23:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark02.localdomain:36253 (size: 19.4 KB, free: 5.5 GB)
17/06/30 08:23:31 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 5, sd-spark04.localdomain, partition 4,ANY, 2231 bytes)
17/06/30 08:23:32 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark05.localdomain:34004) with ID 2
17/06/30 08:23:32 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 6, sd-spark05.localdomain, partition 5,NODE_LOCAL, 2231 bytes)
17/06/30 08:23:32 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark05.localdomain:38332 with 5.5 GB RAM, BlockManagerId(2, sd-spark05.localdomain, 38332)
17/06/30 08:23:32 INFO SparkDeploySchedulerBackend: Registered executor NettyRpcEndpointRef(null) (sd-spark03.localdomain:35696) with ID 4
17/06/30 08:23:32 INFO BlockManagerMasterEndpoint: Registering block manager sd-spark03.localdomain:33317 with 5.5 GB RAM, BlockManagerId(4, sd-spark03.localdomain, 33317)
17/06/30 08:23:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on sd-spark05.localdomain:38332 (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:23:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on sd-spark05.localdomain:38332 (size: 19.4 KB, free: 5.5 GB)
17/06/30 08:23:33 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 4) in 5480 ms on sd-spark06.localdomain (1/7)
17/06/30 08:23:41 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 0) in 13416 ms on sd-spark04.localdomain (2/7)
17/06/30 08:23:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 1) in 14073 ms on sd-spark02.localdomain (3/7)
17/06/30 08:23:42 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 14084 ms on sd-spark02.localdomain (4/7)
17/06/30 08:23:42 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 5) in 10649 ms on sd-spark04.localdomain (5/7)
17/06/30 08:23:42 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 14330 ms on sd-spark06.localdomain (6/7)
17/06/30 08:23:45 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 6) in 12882 ms on sd-spark05.localdomain (7/7)
17/06/30 08:23:45 INFO DAGScheduler: ShuffleMapStage 0 (mapPartitions at ALS.scala:837) finished in 13780.541 s
17/06/30 08:23:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/06/30 08:23:45 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:23:45 INFO DAGScheduler: running: Set()
17/06/30 08:23:45 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ResultStage 2)
17/06/30 08:23:45 INFO DAGScheduler: failed: Set()
17/06/30 08:23:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080), which has no missing parents
17/06/30 08:23:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 243.6 KB)
17/06/30 08:23:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.5 KB, free 247.1 KB)
17/06/30 08:23:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 163.221.29.42:45435 (size: 3.5 KB, free: 511.1 MB)
17/06/30 08:23:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1006
17/06/30 08:23:45 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at map at ALS.scala:1080)
17/06/30 08:23:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 7 tasks
17/06/30 08:23:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 7, sd-spark02.localdomain, partition 0,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 8, sd-spark04.localdomain, partition 1,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:45 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 9, sd-spark02.localdomain, partition 2,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:45 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 10, sd-spark04.localdomain, partition 3,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.5 KB, free: 5.5 GB)
17/06/30 08:23:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.5 KB, free: 5.5 GB)
17/06/30 08:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark02.localdomain:42198
17/06/30 08:23:45 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 206 bytes
17/06/30 08:23:45 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 1 to sd-spark04.localdomain:40512
17/06/30 08:23:45 INFO BlockManagerInfo: Added rdd_6_1 in memory on sd-spark04.localdomain:42799 (size: 16.0 B, free: 5.5 GB)
17/06/30 08:23:45 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 11, sd-spark04.localdomain, partition 4,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 8) in 218 ms on sd-spark04.localdomain (1/7)
17/06/30 08:23:46 INFO BlockManagerInfo: Added rdd_6_3 in memory on sd-spark04.localdomain:42799 (size: 69.5 MB, free: 5.5 GB)
17/06/30 08:23:46 INFO BlockManagerInfo: Added rdd_6_2 in memory on sd-spark02.localdomain:36253 (size: 70.1 MB, free: 5.5 GB)
17/06/30 08:23:46 INFO BlockManagerInfo: Added rdd_6_4 in memory on sd-spark04.localdomain:42799 (size: 70.0 MB, free: 5.4 GB)
17/06/30 08:23:47 INFO BlockManagerInfo: Added rdd_6_0 in memory on sd-spark02.localdomain:36253 (size: 140.0 MB, free: 5.3 GB)
17/06/30 08:23:47 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 12, sd-spark04.localdomain, partition 5,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:47 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 11) in 2460 ms on sd-spark04.localdomain (2/7)
17/06/30 08:23:48 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 13, sd-spark02.localdomain, partition 6,NODE_LOCAL, 1949 bytes)
17/06/30 08:23:48 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 9) in 2766 ms on sd-spark02.localdomain (3/7)
17/06/30 08:23:48 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 10) in 2825 ms on sd-spark04.localdomain (4/7)
17/06/30 08:23:49 INFO BlockManagerInfo: Added rdd_6_5 in memory on sd-spark04.localdomain:42799 (size: 140.1 MB, free: 5.3 GB)
17/06/30 08:23:50 INFO BlockManagerInfo: Added rdd_6_6 in memory on sd-spark02.localdomain:36253 (size: 139.8 MB, free: 5.2 GB)
17/06/30 08:23:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 7) in 4986 ms on sd-spark02.localdomain (5/7)
17/06/30 08:23:51 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 12) in 3627 ms on sd-spark04.localdomain (6/7)
17/06/30 08:23:52 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 13) in 4153 ms on sd-spark02.localdomain (7/7)
17/06/30 08:23:52 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/06/30 08:23:52 INFO DAGScheduler: ShuffleMapStage 1 (map at ALS.scala:1080) finished in 6.918 s
17/06/30 08:23:52 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:23:52 INFO DAGScheduler: running: Set()
17/06/30 08:23:52 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/06/30 08:23:52 INFO DAGScheduler: failed: Set()
17/06/30 08:23:52 INFO DAGScheduler: Submitting ResultStage 2 (userOutBlocks MapPartitionsRDD[10] at mapValues at ALS.scala:1117), which has no missing parents
17/06/30 08:23:52 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.4 KB, free 254.5 KB)
17/06/30 08:23:52 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 258.1 KB)
17/06/30 08:23:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 163.221.29.42:45435 (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:23:52 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1006
17/06/30 08:23:52 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 2 (userOutBlocks MapPartitionsRDD[10] at mapValues at ALS.scala:1117)
17/06/30 08:23:52 INFO TaskSchedulerImpl: Adding task set 2.0 with 3 tasks
17/06/30 08:23:52 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 14, sd-spark02.localdomain, partition 0,NODE_LOCAL, 1960 bytes)
17/06/30 08:23:52 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 15, sd-spark04.localdomain, partition 1,NODE_LOCAL, 1960 bytes)
17/06/30 08:23:52 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 16, sd-spark02.localdomain, partition 2,NODE_LOCAL, 1960 bytes)
17/06/30 08:23:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.7 KB, free: 5.2 GB)
17/06/30 08:23:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to sd-spark02.localdomain:42198
17/06/30 08:23:52 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 194 bytes
17/06/30 08:23:52 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.7 KB, free: 5.3 GB)
17/06/30 08:23:52 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 0 to sd-spark04.localdomain:40512
17/06/30 08:24:07 INFO BlockManagerInfo: Added rdd_9_1 in memory on sd-spark04.localdomain:42799 (size: 140.8 MB, free: 5.1 GB)
17/06/30 08:24:07 INFO BlockManagerInfo: Added rdd_10_1 in memory on sd-spark04.localdomain:42799 (size: 1839.8 KB, free: 5.1 GB)
17/06/30 08:24:07 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 15) in 15142 ms on sd-spark04.localdomain (1/3)
17/06/30 08:24:12 INFO BlockManagerInfo: Added rdd_9_0 in memory on sd-spark02.localdomain:36253 (size: 141.3 MB, free: 5.1 GB)
17/06/30 08:24:12 INFO BlockManagerInfo: Added rdd_10_0 in memory on sd-spark02.localdomain:36253 (size: 1842.4 KB, free: 5.0 GB)
17/06/30 08:24:12 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 14) in 19871 ms on sd-spark02.localdomain (2/3)
17/06/30 08:24:12 INFO BlockManagerInfo: Added rdd_9_2 in memory on sd-spark02.localdomain:36253 (size: 141.2 MB, free: 4.9 GB)
17/06/30 08:24:12 INFO BlockManagerInfo: Added rdd_10_2 in memory on sd-spark02.localdomain:36253 (size: 1840.7 KB, free: 4.9 GB)
17/06/30 08:24:12 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 16) in 20119 ms on sd-spark02.localdomain (3/3)
17/06/30 08:24:12 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/06/30 08:24:12 INFO DAGScheduler: ResultStage 2 (count at ALS.scala:596) finished in 20.121 s
17/06/30 08:24:12 INFO DAGScheduler: Job 0 finished: count at ALS.scala:596, took 13808.008290 s
17/06/30 08:24:12 INFO SparkContext: Starting job: count at ALS.scala:604
17/06/30 08:24:12 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 206 bytes
17/06/30 08:24:12 INFO DAGScheduler: Registering RDD 12 (map at ALS.scala:1080)
17/06/30 08:24:12 INFO DAGScheduler: Got job 1 (count at ALS.scala:604) with 3 output partitions
17/06/30 08:24:12 INFO DAGScheduler: Final stage: ResultStage 5 (count at ALS.scala:604)
17/06/30 08:24:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/06/30 08:24:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/06/30 08:24:12 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at map at ALS.scala:1080), which has no missing parents
17/06/30 08:24:12 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 6.9 KB, free 265.1 KB)
17/06/30 08:24:12 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.5 KB, free 268.6 KB)
17/06/30 08:24:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 163.221.29.42:45435 (size: 3.5 KB, free: 511.1 MB)
17/06/30 08:24:12 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1006
17/06/30 08:24:12 INFO DAGScheduler: Submitting 7 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at map at ALS.scala:1080)
17/06/30 08:24:12 INFO TaskSchedulerImpl: Adding task set 4.0 with 7 tasks
17/06/30 08:24:12 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 17, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:12 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 18, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:12 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 19, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:12 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 20, sd-spark04.localdomain, partition 3,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.5 KB, free: 5.1 GB)
17/06/30 08:24:12 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.5 KB, free: 4.9 GB)
17/06/30 08:24:12 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 21, sd-spark04.localdomain, partition 4,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:12 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 18) in 57 ms on sd-spark04.localdomain (1/7)
17/06/30 08:24:14 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 22, sd-spark04.localdomain, partition 5,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:14 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 20) in 1345 ms on sd-spark04.localdomain (2/7)
17/06/30 08:24:14 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 21) in 1337 ms on sd-spark04.localdomain (3/7)
17/06/30 08:24:14 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 23, sd-spark02.localdomain, partition 6,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:14 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 19) in 1456 ms on sd-spark02.localdomain (4/7)
17/06/30 08:24:15 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 17) in 2997 ms on sd-spark02.localdomain (5/7)
17/06/30 08:24:16 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 22) in 2592 ms on sd-spark04.localdomain (6/7)
17/06/30 08:24:17 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 23) in 2983 ms on sd-spark02.localdomain (7/7)
17/06/30 08:24:17 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/06/30 08:24:17 INFO DAGScheduler: ShuffleMapStage 4 (map at ALS.scala:1080) finished in 4.439 s
17/06/30 08:24:17 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:24:17 INFO DAGScheduler: running: Set()
17/06/30 08:24:17 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/06/30 08:24:17 INFO DAGScheduler: failed: Set()
17/06/30 08:24:17 INFO DAGScheduler: Submitting ResultStage 5 (itemOutBlocks MapPartitionsRDD[15] at mapValues at ALS.scala:1117), which has no missing parents
17/06/30 08:24:17 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.5 KB, free 276.1 KB)
17/06/30 08:24:17 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 279.8 KB)
17/06/30 08:24:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 163.221.29.42:45435 (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:24:17 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1006
17/06/30 08:24:17 INFO DAGScheduler: Submitting 3 missing tasks from ResultStage 5 (itemOutBlocks MapPartitionsRDD[15] at mapValues at ALS.scala:1117)
17/06/30 08:24:17 INFO TaskSchedulerImpl: Adding task set 5.0 with 3 tasks
17/06/30 08:24:17 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 24, sd-spark04.localdomain, partition 0,NODE_LOCAL, 1960 bytes)
17/06/30 08:24:17 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 25, sd-spark02.localdomain, partition 1,NODE_LOCAL, 1960 bytes)
17/06/30 08:24:17 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 26, sd-spark04.localdomain, partition 2,NODE_LOCAL, 1960 bytes)
17/06/30 08:24:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.7 KB, free: 5.1 GB)
17/06/30 08:24:17 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.7 KB, free: 4.9 GB)
17/06/30 08:24:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to sd-spark04.localdomain:40512
17/06/30 08:24:17 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 197 bytes
17/06/30 08:24:17 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 2 to sd-spark02.localdomain:42198
17/06/30 08:24:30 INFO BlockManagerInfo: Added rdd_14_2 in memory on sd-spark04.localdomain:42799 (size: 139.3 MB, free: 5.0 GB)
17/06/30 08:24:30 INFO BlockManagerInfo: Added rdd_15_2 in memory on sd-spark04.localdomain:42799 (size: 69.6 KB, free: 5.0 GB)
17/06/30 08:24:30 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 26) in 12993 ms on sd-spark04.localdomain (1/3)
17/06/30 08:24:30 INFO BlockManagerInfo: Added rdd_14_1 in memory on sd-spark02.localdomain:36253 (size: 140.0 MB, free: 4.8 GB)
17/06/30 08:24:30 INFO BlockManagerInfo: Added rdd_15_1 in memory on sd-spark02.localdomain:36253 (size: 69.6 KB, free: 4.8 GB)
17/06/30 08:24:30 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 25) in 13676 ms on sd-spark02.localdomain (2/3)
17/06/30 08:24:31 INFO BlockManagerInfo: Added rdd_14_0 in memory on sd-spark04.localdomain:42799 (size: 140.5 MB, free: 4.8 GB)
17/06/30 08:24:31 INFO BlockManagerInfo: Added rdd_15_0 in memory on sd-spark04.localdomain:42799 (size: 69.5 KB, free: 4.8 GB)
17/06/30 08:24:31 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 24) in 14707 ms on sd-spark04.localdomain (3/3)
17/06/30 08:24:31 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/06/30 08:24:31 INFO DAGScheduler: ResultStage 5 (count at ALS.scala:604) finished in 14.707 s
17/06/30 08:24:31 INFO DAGScheduler: Job 1 finished: count at ALS.scala:604, took 19.324003 s
17/06/30 08:24:32 INFO SparkContext: Starting job: count at ALS.scala:263
17/06/30 08:24:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 206 bytes
17/06/30 08:24:34 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 194 bytes
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 16 (map at ALS.scala:752)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 21 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 30 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 39 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 48 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 163.221.29.42:45435 in memory (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 57 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 66 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 75 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 84 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 93 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 102 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 111 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 120 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 129 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 138 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 147 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 156 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 165 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 174 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 183 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 192 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 201 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 210 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 219 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 228 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 237 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 246 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 255 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 264 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 273 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Registering RDD 282 (flatMap at ALS.scala:1170)
17/06/30 08:24:34 INFO DAGScheduler: Got job 2 (count at ALS.scala:263) with 3 output partitions
17/06/30 08:24:34 INFO DAGScheduler: Final stage: ResultStage 41 (count at ALS.scala:263)
17/06/30 08:24:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 9, ShuffleMapStage 40)
17/06/30 08:24:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 40)
17/06/30 08:24:34 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[16] at map at ALS.scala:752), which has no missing parents
17/06/30 08:24:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 7.4 KB, free 276.0 KB)
17/06/30 08:24:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.7 KB, free 279.7 KB)
17/06/30 08:24:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 163.221.29.42:45435 (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:24:34 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1006
17/06/30 08:24:34 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[16] at map at ALS.scala:752)
17/06/30 08:24:34 INFO TaskSchedulerImpl: Adding task set 10.0 with 3 tasks
17/06/30 08:24:34 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 27, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:34 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 28, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:34 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 29, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 1949 bytes)
17/06/30 08:24:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_5_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO ContextCleaner: Cleaned accumulator 5
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 163.221.29.42:45435 in memory (size: 3.5 KB, free: 511.1 MB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.5 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_4_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.5 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO ContextCleaner: Cleaned accumulator 4
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 163.221.29.42:45435 in memory (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 163.221.29.42:45435 in memory (size: 3.5 KB, free: 511.1 MB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.5 KB, free: 4.8 GB)
17/06/30 08:24:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.5 KB, free: 4.8 GB)
17/06/30 08:24:35 INFO TaskSetManager: Finished task 1.0 in stage 10.0 (TID 28) in 841 ms on sd-spark04.localdomain (1/3)
17/06/30 08:24:35 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 27) in 1319 ms on sd-spark02.localdomain (2/3)
17/06/30 08:24:35 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 29) in 1360 ms on sd-spark02.localdomain (3/3)
17/06/30 08:24:35 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/06/30 08:24:35 INFO DAGScheduler: ShuffleMapStage 10 (map at ALS.scala:752) finished in 1.364 s
17/06/30 08:24:35 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:24:35 INFO DAGScheduler: running: Set()
17/06/30 08:24:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 14, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ShuffleMapStage 11, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 12, ShuffleMapStage 34, ShuffleMapStage 13, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:24:35 INFO DAGScheduler: failed: Set()
17/06/30 08:24:35 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[21] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:24:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 8.4 KB, free 256.3 KB)
17/06/30 08:24:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.9 KB, free 260.2 KB)
17/06/30 08:24:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 163.221.29.42:45435 (size: 3.9 KB, free: 511.1 MB)
17/06/30 08:24:35 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1006
17/06/30 08:24:35 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[21] at flatMap at ALS.scala:1170)
17/06/30 08:24:35 INFO TaskSchedulerImpl: Adding task set 11.0 with 3 tasks
17/06/30 08:24:35 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 30, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2176 bytes)
17/06/30 08:24:35 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 31, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2176 bytes)
17/06/30 08:24:35 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 32, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2176 bytes)
17/06/30 08:24:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sd-spark04.localdomain:42799 (size: 3.9 KB, free: 4.8 GB)
17/06/30 08:24:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to sd-spark04.localdomain:40512
17/06/30 08:24:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 33 is 179 bytes
17/06/30 08:24:36 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on sd-spark02.localdomain:36253 (size: 3.9 KB, free: 4.8 GB)
17/06/30 08:24:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 33 to sd-spark02.localdomain:42198
17/06/30 08:24:37 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 30) in 1612 ms on sd-spark04.localdomain (1/3)
17/06/30 08:24:39 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 31) in 3175 ms on sd-spark02.localdomain (2/3)
17/06/30 08:24:39 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 32) in 3997 ms on sd-spark02.localdomain (3/3)
17/06/30 08:24:39 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/06/30 08:24:39 INFO DAGScheduler: ShuffleMapStage 11 (flatMap at ALS.scala:1170) finished in 4.000 s
17/06/30 08:24:39 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:24:39 INFO DAGScheduler: running: Set()
17/06/30 08:24:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 14, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 12, ShuffleMapStage 34, ShuffleMapStage 13, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:24:39 INFO DAGScheduler: failed: Set()
17/06/30 08:24:39 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[30] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:24:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 10.6 KB, free 270.8 KB)
17/06/30 08:24:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 4.6 KB, free 275.5 KB)
17/06/30 08:24:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 163.221.29.42:45435 (size: 4.6 KB, free: 511.1 MB)
17/06/30 08:24:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1006
17/06/30 08:24:39 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[30] at flatMap at ALS.scala:1170)
17/06/30 08:24:39 INFO TaskSchedulerImpl: Adding task set 12.0 with 3 tasks
17/06/30 08:24:39 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 33, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:24:39 INFO TaskSetManager: Starting task 1.0 in stage 12.0 (TID 34, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:24:39 INFO TaskSetManager: Starting task 2.0 in stage 12.0 (TID 35, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:24:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark04.localdomain:42799 (size: 4.6 KB, free: 4.8 GB)
17/06/30 08:24:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to sd-spark04.localdomain:40512
17/06/30 08:24:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 32 is 171 bytes
17/06/30 08:24:40 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on sd-spark02.localdomain:36253 (size: 4.6 KB, free: 4.8 GB)
17/06/30 08:24:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 32 to sd-spark02.localdomain:42198
17/06/30 08:25:07 INFO TaskSetManager: Finished task 2.0 in stage 12.0 (TID 35) in 27738 ms on sd-spark04.localdomain (1/3)
17/06/30 08:25:08 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 33) in 28122 ms on sd-spark04.localdomain (2/3)
17/06/30 08:25:08 INFO TaskSetManager: Finished task 1.0 in stage 12.0 (TID 34) in 28229 ms on sd-spark02.localdomain (3/3)
17/06/30 08:25:08 INFO DAGScheduler: ShuffleMapStage 12 (flatMap at ALS.scala:1170) finished in 28.229 s
17/06/30 08:25:08 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:25:08 INFO DAGScheduler: running: Set()
17/06/30 08:25:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 14, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 13, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:25:08 INFO DAGScheduler: failed: Set()
17/06/30 08:25:08 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/06/30 08:25:08 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[39] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:25:08 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.5 KB, free 287.0 KB)
17/06/30 08:25:08 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 4.8 KB, free 291.8 KB)
17/06/30 08:25:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 163.221.29.42:45435 (size: 4.8 KB, free: 511.1 MB)
17/06/30 08:25:08 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1006
17/06/30 08:25:08 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[39] at flatMap at ALS.scala:1170)
17/06/30 08:25:08 INFO TaskSchedulerImpl: Adding task set 13.0 with 3 tasks
17/06/30 08:25:08 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 36, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:08 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 37, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:08 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 38, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on sd-spark04.localdomain:42799 (size: 4.8 KB, free: 4.8 GB)
17/06/30 08:25:08 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on sd-spark02.localdomain:36253 (size: 4.8 KB, free: 4.8 GB)
17/06/30 08:25:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to sd-spark04.localdomain:40512
17/06/30 08:25:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 31 is 171 bytes
17/06/30 08:25:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 31 to sd-spark02.localdomain:42198
17/06/30 08:25:36 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 36) in 27981 ms on sd-spark04.localdomain (1/3)
17/06/30 08:25:39 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 37) in 31584 ms on sd-spark02.localdomain (2/3)
17/06/30 08:25:40 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 38) in 32399 ms on sd-spark02.localdomain (3/3)
17/06/30 08:25:40 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/06/30 08:25:40 INFO DAGScheduler: ShuffleMapStage 13 (flatMap at ALS.scala:1170) finished in 32.400 s
17/06/30 08:25:40 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:25:40 INFO DAGScheduler: running: Set()
17/06/30 08:25:40 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 14, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:25:40 INFO DAGScheduler: failed: Set()
17/06/30 08:25:40 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[48] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:25:40 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 12.4 KB, free 304.2 KB)
17/06/30 08:25:40 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 5.0 KB, free 309.2 KB)
17/06/30 08:25:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 163.221.29.42:45435 (size: 5.0 KB, free: 511.1 MB)
17/06/30 08:25:40 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1006
17/06/30 08:25:40 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[48] at flatMap at ALS.scala:1170)
17/06/30 08:25:40 INFO TaskSchedulerImpl: Adding task set 14.0 with 3 tasks
17/06/30 08:25:40 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 39, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:40 INFO TaskSetManager: Starting task 1.0 in stage 14.0 (TID 40, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:40 INFO TaskSetManager: Starting task 2.0 in stage 14.0 (TID 41, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:25:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.0 KB, free: 4.8 GB)
17/06/30 08:25:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to sd-spark04.localdomain:40512
17/06/30 08:25:40 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 30 is 171 bytes
17/06/30 08:25:40 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.0 KB, free: 4.8 GB)
17/06/30 08:25:40 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 30 to sd-spark02.localdomain:42198
17/06/30 08:26:06 INFO TaskSetManager: Finished task 1.0 in stage 14.0 (TID 40) in 26280 ms on sd-spark02.localdomain (1/3)
17/06/30 08:26:07 INFO TaskSetManager: Finished task 2.0 in stage 14.0 (TID 41) in 26766 ms on sd-spark04.localdomain (2/3)
17/06/30 08:26:07 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 39) in 26770 ms on sd-spark04.localdomain (3/3)
17/06/30 08:26:07 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/06/30 08:26:07 INFO DAGScheduler: ShuffleMapStage 14 (flatMap at ALS.scala:1170) finished in 26.771 s
17/06/30 08:26:07 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:26:07 INFO DAGScheduler: running: Set()
17/06/30 08:26:07 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 15, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:26:07 INFO DAGScheduler: failed: Set()
17/06/30 08:26:07 INFO DAGScheduler: Submitting ShuffleMapStage 15 (MapPartitionsRDD[57] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:26:07 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 13.3 KB, free 322.5 KB)
17/06/30 08:26:07 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.2 KB, free 327.7 KB)
17/06/30 08:26:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 163.221.29.42:45435 (size: 5.2 KB, free: 511.1 MB)
17/06/30 08:26:07 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1006
17/06/30 08:26:07 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 15 (MapPartitionsRDD[57] at flatMap at ALS.scala:1170)
17/06/30 08:26:07 INFO TaskSchedulerImpl: Adding task set 15.0 with 3 tasks
17/06/30 08:26:07 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 42, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:07 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 43, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:07 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 44, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.2 KB, free: 4.8 GB)
17/06/30 08:26:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to sd-spark04.localdomain:40512
17/06/30 08:26:07 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 29 is 174 bytes
17/06/30 08:26:07 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.2 KB, free: 4.8 GB)
17/06/30 08:26:07 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 29 to sd-spark02.localdomain:42198
17/06/30 08:26:34 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 43) in 27323 ms on sd-spark04.localdomain (1/3)
17/06/30 08:26:37 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 44) in 30531 ms on sd-spark02.localdomain (2/3)
17/06/30 08:26:41 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 42) in 34106 ms on sd-spark02.localdomain (3/3)
17/06/30 08:26:41 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/06/30 08:26:41 INFO DAGScheduler: ShuffleMapStage 15 (flatMap at ALS.scala:1170) finished in 34.107 s
17/06/30 08:26:41 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:26:41 INFO DAGScheduler: running: Set()
17/06/30 08:26:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 16, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:26:41 INFO DAGScheduler: failed: Set()
17/06/30 08:26:41 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[66] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:26:41 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 14.1 KB, free 341.8 KB)
17/06/30 08:26:41 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.4 KB, free 347.2 KB)
17/06/30 08:26:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 163.221.29.42:45435 (size: 5.4 KB, free: 511.1 MB)
17/06/30 08:26:41 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1006
17/06/30 08:26:41 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[66] at flatMap at ALS.scala:1170)
17/06/30 08:26:41 INFO TaskSchedulerImpl: Adding task set 16.0 with 3 tasks
17/06/30 08:26:41 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 45, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:41 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 46, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:41 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 47, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:26:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.4 KB, free: 4.8 GB)
17/06/30 08:26:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to sd-spark04.localdomain:40512
17/06/30 08:26:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 28 is 171 bytes
17/06/30 08:26:41 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.4 KB, free: 4.8 GB)
17/06/30 08:26:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 28 to sd-spark02.localdomain:42198
17/06/30 08:27:08 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 47) in 26732 ms on sd-spark04.localdomain (1/3)
17/06/30 08:27:08 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 46) in 27262 ms on sd-spark02.localdomain (2/3)
17/06/30 08:27:09 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 45) in 27964 ms on sd-spark04.localdomain (3/3)
17/06/30 08:27:09 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/06/30 08:27:09 INFO DAGScheduler: ShuffleMapStage 16 (flatMap at ALS.scala:1170) finished in 27.965 s
17/06/30 08:27:09 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:27:09 INFO DAGScheduler: running: Set()
17/06/30 08:27:09 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 17, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:27:09 INFO DAGScheduler: failed: Set()
17/06/30 08:27:09 INFO DAGScheduler: Submitting ShuffleMapStage 17 (MapPartitionsRDD[75] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:27:09 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 15.0 KB, free 362.3 KB)
17/06/30 08:27:09 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.6 KB, free 367.8 KB)
17/06/30 08:27:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 163.221.29.42:45435 (size: 5.6 KB, free: 511.1 MB)
17/06/30 08:27:09 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1006
17/06/30 08:27:09 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 17 (MapPartitionsRDD[75] at flatMap at ALS.scala:1170)
17/06/30 08:27:09 INFO TaskSchedulerImpl: Adding task set 17.0 with 3 tasks
17/06/30 08:27:09 INFO TaskSetManager: Starting task 1.0 in stage 17.0 (TID 48, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:09 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 49, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:09 INFO TaskSetManager: Starting task 2.0 in stage 17.0 (TID 50, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.6 KB, free: 4.8 GB)
17/06/30 08:27:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to sd-spark04.localdomain:40512
17/06/30 08:27:09 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 27 is 174 bytes
17/06/30 08:27:09 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.6 KB, free: 4.8 GB)
17/06/30 08:27:09 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 27 to sd-spark02.localdomain:42198
17/06/30 08:27:37 INFO TaskSetManager: Finished task 1.0 in stage 17.0 (TID 48) in 27885 ms on sd-spark04.localdomain (1/3)
17/06/30 08:27:41 INFO TaskSetManager: Finished task 2.0 in stage 17.0 (TID 50) in 32429 ms on sd-spark02.localdomain (2/3)
17/06/30 08:27:41 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 49) in 32467 ms on sd-spark02.localdomain (3/3)
17/06/30 08:27:41 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/06/30 08:27:41 INFO DAGScheduler: ShuffleMapStage 17 (flatMap at ALS.scala:1170) finished in 32.468 s
17/06/30 08:27:41 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:27:41 INFO DAGScheduler: running: Set()
17/06/30 08:27:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 18, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:27:41 INFO DAGScheduler: failed: Set()
17/06/30 08:27:41 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[84] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:27:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 15.9 KB, free 383.7 KB)
17/06/30 08:27:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.7 KB, free 389.5 KB)
17/06/30 08:27:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 163.221.29.42:45435 (size: 5.7 KB, free: 511.1 MB)
17/06/30 08:27:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1006
17/06/30 08:27:41 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[84] at flatMap at ALS.scala:1170)
17/06/30 08:27:41 INFO TaskSchedulerImpl: Adding task set 18.0 with 3 tasks
17/06/30 08:27:41 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 51, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:41 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 52, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:41 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 53, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:27:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.7 KB, free: 4.8 GB)
17/06/30 08:27:42 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.7 KB, free: 4.8 GB)
17/06/30 08:27:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to sd-spark04.localdomain:40512
17/06/30 08:27:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 26 is 171 bytes
17/06/30 08:27:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 26 to sd-spark02.localdomain:42198
17/06/30 08:28:07 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 51) in 25976 ms on sd-spark02.localdomain (1/3)
17/06/30 08:28:09 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 53) in 27635 ms on sd-spark04.localdomain (2/3)
17/06/30 08:28:10 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 52) in 28101 ms on sd-spark04.localdomain (3/3)
17/06/30 08:28:10 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/06/30 08:28:10 INFO DAGScheduler: ShuffleMapStage 18 (flatMap at ALS.scala:1170) finished in 28.101 s
17/06/30 08:28:10 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:28:10 INFO DAGScheduler: running: Set()
17/06/30 08:28:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 19, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:28:10 INFO DAGScheduler: failed: Set()
17/06/30 08:28:10 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[93] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:28:10 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 16.8 KB, free 406.2 KB)
17/06/30 08:28:10 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.9 KB, free 412.1 KB)
17/06/30 08:28:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 163.221.29.42:45435 (size: 5.9 KB, free: 511.1 MB)
17/06/30 08:28:10 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1006
17/06/30 08:28:10 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[93] at flatMap at ALS.scala:1170)
17/06/30 08:28:10 INFO TaskSchedulerImpl: Adding task set 19.0 with 3 tasks
17/06/30 08:28:10 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 54, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:10 INFO TaskSetManager: Starting task 1.0 in stage 19.0 (TID 55, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:10 INFO TaskSetManager: Starting task 2.0 in stage 19.0 (TID 56, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on sd-spark02.localdomain:36253 (size: 5.9 KB, free: 4.8 GB)
17/06/30 08:28:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to sd-spark02.localdomain:42198
17/06/30 08:28:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 25 is 174 bytes
17/06/30 08:28:10 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on sd-spark04.localdomain:42799 (size: 5.9 KB, free: 4.8 GB)
17/06/30 08:28:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 25 to sd-spark04.localdomain:40512
17/06/30 08:28:38 INFO TaskSetManager: Finished task 1.0 in stage 19.0 (TID 55) in 28270 ms on sd-spark04.localdomain (1/3)
17/06/30 08:28:42 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 54) in 32452 ms on sd-spark02.localdomain (2/3)
17/06/30 08:28:42 INFO TaskSetManager: Finished task 2.0 in stage 19.0 (TID 56) in 32841 ms on sd-spark02.localdomain (3/3)
17/06/30 08:28:42 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/06/30 08:28:42 INFO DAGScheduler: ShuffleMapStage 19 (flatMap at ALS.scala:1170) finished in 32.843 s
17/06/30 08:28:42 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:28:42 INFO DAGScheduler: running: Set()
17/06/30 08:28:42 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 20, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:28:42 INFO DAGScheduler: failed: Set()
17/06/30 08:28:42 INFO DAGScheduler: Submitting ShuffleMapStage 20 (MapPartitionsRDD[102] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:28:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 17.7 KB, free 429.8 KB)
17/06/30 08:28:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 6.1 KB, free 435.9 KB)
17/06/30 08:28:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 163.221.29.42:45435 (size: 6.1 KB, free: 511.0 MB)
17/06/30 08:28:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1006
17/06/30 08:28:42 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 20 (MapPartitionsRDD[102] at flatMap at ALS.scala:1170)
17/06/30 08:28:42 INFO TaskSchedulerImpl: Adding task set 20.0 with 3 tasks
17/06/30 08:28:42 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 57, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:42 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 58, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:42 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 59, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:28:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.1 KB, free: 4.8 GB)
17/06/30 08:28:42 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to sd-spark04.localdomain:40512
17/06/30 08:28:42 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 24 is 171 bytes
17/06/30 08:28:43 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.1 KB, free: 4.8 GB)
17/06/30 08:28:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 24 to sd-spark02.localdomain:42198
17/06/30 08:29:09 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 59) in 26687 ms on sd-spark04.localdomain (1/3)
17/06/30 08:29:09 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 58) in 26898 ms on sd-spark02.localdomain (2/3)
17/06/30 08:29:10 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 57) in 27222 ms on sd-spark04.localdomain (3/3)
17/06/30 08:29:10 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/06/30 08:29:10 INFO DAGScheduler: ShuffleMapStage 20 (flatMap at ALS.scala:1170) finished in 27.222 s
17/06/30 08:29:10 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:29:10 INFO DAGScheduler: running: Set()
17/06/30 08:29:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 21, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:29:10 INFO DAGScheduler: failed: Set()
17/06/30 08:29:10 INFO DAGScheduler: Submitting ShuffleMapStage 21 (MapPartitionsRDD[111] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:29:10 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.5 KB, free 454.4 KB)
17/06/30 08:29:10 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 6.3 KB, free 460.7 KB)
17/06/30 08:29:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 163.221.29.42:45435 (size: 6.3 KB, free: 511.0 MB)
17/06/30 08:29:10 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1006
17/06/30 08:29:10 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 21 (MapPartitionsRDD[111] at flatMap at ALS.scala:1170)
17/06/30 08:29:10 INFO TaskSchedulerImpl: Adding task set 21.0 with 3 tasks
17/06/30 08:29:10 INFO TaskSetManager: Starting task 1.0 in stage 21.0 (TID 60, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:10 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 61, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:10 INFO TaskSetManager: Starting task 2.0 in stage 21.0 (TID 62, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.3 KB, free: 4.8 GB)
17/06/30 08:29:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to sd-spark04.localdomain:40512
17/06/30 08:29:10 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 23 is 174 bytes
17/06/30 08:29:10 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.3 KB, free: 4.8 GB)
17/06/30 08:29:10 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 23 to sd-spark02.localdomain:42198
17/06/30 08:29:37 INFO TaskSetManager: Finished task 1.0 in stage 21.0 (TID 60) in 27792 ms on sd-spark04.localdomain (1/3)
17/06/30 08:29:42 INFO TaskSetManager: Finished task 2.0 in stage 21.0 (TID 62) in 32178 ms on sd-spark02.localdomain (2/3)
17/06/30 08:29:44 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 61) in 34072 ms on sd-spark02.localdomain (3/3)
17/06/30 08:29:44 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/06/30 08:29:44 INFO DAGScheduler: ShuffleMapStage 21 (flatMap at ALS.scala:1170) finished in 34.074 s
17/06/30 08:29:44 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:29:44 INFO DAGScheduler: running: Set()
17/06/30 08:29:44 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 22, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:29:44 INFO DAGScheduler: failed: Set()
17/06/30 08:29:44 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[120] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:29:44 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 19.4 KB, free 480.1 KB)
17/06/30 08:29:44 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.5 KB, free 486.6 KB)
17/06/30 08:29:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 163.221.29.42:45435 (size: 6.5 KB, free: 511.0 MB)
17/06/30 08:29:44 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1006
17/06/30 08:29:44 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[120] at flatMap at ALS.scala:1170)
17/06/30 08:29:44 INFO TaskSchedulerImpl: Adding task set 22.0 with 3 tasks
17/06/30 08:29:44 INFO TaskSetManager: Starting task 1.0 in stage 22.0 (TID 63, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:44 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 64, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:44 INFO TaskSetManager: Starting task 2.0 in stage 22.0 (TID 65, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:29:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.5 KB, free: 4.8 GB)
17/06/30 08:29:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to sd-spark04.localdomain:40512
17/06/30 08:29:44 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 22 is 171 bytes
17/06/30 08:29:44 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.5 KB, free: 4.8 GB)
17/06/30 08:29:44 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 22 to sd-spark02.localdomain:42198
17/06/30 08:30:10 INFO TaskSetManager: Finished task 2.0 in stage 22.0 (TID 65) in 26501 ms on sd-spark04.localdomain (1/3)
17/06/30 08:30:11 INFO TaskSetManager: Finished task 1.0 in stage 22.0 (TID 63) in 26760 ms on sd-spark02.localdomain (2/3)
17/06/30 08:30:11 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 64) in 27044 ms on sd-spark04.localdomain (3/3)
17/06/30 08:30:11 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/06/30 08:30:11 INFO DAGScheduler: ShuffleMapStage 22 (flatMap at ALS.scala:1170) finished in 27.044 s
17/06/30 08:30:11 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:30:11 INFO DAGScheduler: running: Set()
17/06/30 08:30:11 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 23, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:30:11 INFO DAGScheduler: failed: Set()
17/06/30 08:30:11 INFO DAGScheduler: Submitting ShuffleMapStage 23 (MapPartitionsRDD[129] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:30:11 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 20.3 KB, free 506.9 KB)
17/06/30 08:30:11 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.6 KB, free 513.5 KB)
17/06/30 08:30:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 163.221.29.42:45435 (size: 6.6 KB, free: 511.0 MB)
17/06/30 08:30:11 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1006
17/06/30 08:30:11 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 23 (MapPartitionsRDD[129] at flatMap at ALS.scala:1170)
17/06/30 08:30:11 INFO TaskSchedulerImpl: Adding task set 23.0 with 3 tasks
17/06/30 08:30:11 INFO TaskSetManager: Starting task 1.0 in stage 23.0 (TID 66, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:11 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 67, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:11 INFO TaskSetManager: Starting task 2.0 in stage 23.0 (TID 68, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.6 KB, free: 4.8 GB)
17/06/30 08:30:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to sd-spark04.localdomain:40512
17/06/30 08:30:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 21 is 174 bytes
17/06/30 08:30:11 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.6 KB, free: 4.8 GB)
17/06/30 08:30:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 21 to sd-spark02.localdomain:42198
17/06/30 08:30:39 INFO TaskSetManager: Finished task 1.0 in stage 23.0 (TID 66) in 27900 ms on sd-spark04.localdomain (1/3)
17/06/30 08:30:43 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 67) in 32180 ms on sd-spark02.localdomain (2/3)
17/06/30 08:30:43 INFO TaskSetManager: Finished task 2.0 in stage 23.0 (TID 68) in 32179 ms on sd-spark02.localdomain (3/3)
17/06/30 08:30:43 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/06/30 08:30:43 INFO DAGScheduler: ShuffleMapStage 23 (flatMap at ALS.scala:1170) finished in 32.181 s
17/06/30 08:30:43 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:30:43 INFO DAGScheduler: running: Set()
17/06/30 08:30:43 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 24, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:30:43 INFO DAGScheduler: failed: Set()
17/06/30 08:30:43 INFO DAGScheduler: Submitting ShuffleMapStage 24 (MapPartitionsRDD[138] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:30:43 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 21.2 KB, free 534.7 KB)
17/06/30 08:30:43 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 6.8 KB, free 541.5 KB)
17/06/30 08:30:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 163.221.29.42:45435 (size: 6.8 KB, free: 511.0 MB)
17/06/30 08:30:43 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1006
17/06/30 08:30:43 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 24 (MapPartitionsRDD[138] at flatMap at ALS.scala:1170)
17/06/30 08:30:43 INFO TaskSchedulerImpl: Adding task set 24.0 with 3 tasks
17/06/30 08:30:43 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 69, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:43 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 70, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:43 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 71, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:30:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.8 KB, free: 4.8 GB)
17/06/30 08:30:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to sd-spark02.localdomain:42198
17/06/30 08:30:43 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 20 is 171 bytes
17/06/30 08:30:43 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.8 KB, free: 4.8 GB)
17/06/30 08:30:43 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 20 to sd-spark04.localdomain:40512
17/06/30 08:31:08 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 69) in 25213 ms on sd-spark02.localdomain (1/3)
17/06/30 08:31:10 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 71) in 27169 ms on sd-spark04.localdomain (2/3)
17/06/30 08:31:10 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 70) in 27447 ms on sd-spark04.localdomain (3/3)
17/06/30 08:31:10 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/06/30 08:31:10 INFO DAGScheduler: ShuffleMapStage 24 (flatMap at ALS.scala:1170) finished in 27.447 s
17/06/30 08:31:10 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:31:10 INFO DAGScheduler: running: Set()
17/06/30 08:31:10 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 25, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:31:10 INFO DAGScheduler: failed: Set()
17/06/30 08:31:10 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[147] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:31:11 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 22.0 KB, free 563.6 KB)
17/06/30 08:31:11 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 6.9 KB, free 570.5 KB)
17/06/30 08:31:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 163.221.29.42:45435 (size: 6.9 KB, free: 511.0 MB)
17/06/30 08:31:11 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1006
17/06/30 08:31:11 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[147] at flatMap at ALS.scala:1170)
17/06/30 08:31:11 INFO TaskSchedulerImpl: Adding task set 25.0 with 3 tasks
17/06/30 08:31:11 INFO TaskSetManager: Starting task 1.0 in stage 25.0 (TID 72, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:11 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 73, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:11 INFO TaskSetManager: Starting task 2.0 in stage 25.0 (TID 74, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on sd-spark04.localdomain:42799 (size: 6.9 KB, free: 4.8 GB)
17/06/30 08:31:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to sd-spark04.localdomain:40512
17/06/30 08:31:11 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 19 is 171 bytes
17/06/30 08:31:11 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on sd-spark02.localdomain:36253 (size: 6.9 KB, free: 4.8 GB)
17/06/30 08:31:11 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 19 to sd-spark02.localdomain:42198
17/06/30 08:31:38 INFO TaskSetManager: Finished task 1.0 in stage 25.0 (TID 72) in 27837 ms on sd-spark04.localdomain (1/3)
17/06/30 08:31:40 INFO TaskSetManager: Finished task 2.0 in stage 25.0 (TID 74) in 29984 ms on sd-spark02.localdomain (2/3)
17/06/30 08:31:41 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 73) in 30485 ms on sd-spark02.localdomain (3/3)
17/06/30 08:31:41 INFO DAGScheduler: ShuffleMapStage 25 (flatMap at ALS.scala:1170) finished in 30.485 s
17/06/30 08:31:41 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:31:41 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/06/30 08:31:41 INFO DAGScheduler: running: Set()
17/06/30 08:31:41 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 26, ShuffleMapStage 27, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:31:41 INFO DAGScheduler: failed: Set()
17/06/30 08:31:41 INFO DAGScheduler: Submitting ShuffleMapStage 26 (MapPartitionsRDD[156] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:31:41 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 22.9 KB, free 593.4 KB)
17/06/30 08:31:41 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 7.2 KB, free 600.6 KB)
17/06/30 08:31:41 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 163.221.29.42:45435 (size: 7.2 KB, free: 511.0 MB)
17/06/30 08:31:41 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:1006
17/06/30 08:31:41 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 26 (MapPartitionsRDD[156] at flatMap at ALS.scala:1170)
17/06/30 08:31:41 INFO TaskSchedulerImpl: Adding task set 26.0 with 3 tasks
17/06/30 08:31:41 INFO TaskSetManager: Starting task 1.0 in stage 26.0 (TID 75, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:41 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 76, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:41 INFO TaskSetManager: Starting task 2.0 in stage 26.0 (TID 77, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:31:41 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on sd-spark04.localdomain:42799 (size: 7.2 KB, free: 4.8 GB)
17/06/30 08:31:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to sd-spark04.localdomain:40512
17/06/30 08:31:41 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 18 is 171 bytes
17/06/30 08:31:41 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on sd-spark02.localdomain:36253 (size: 7.2 KB, free: 4.8 GB)
17/06/30 08:31:41 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 18 to sd-spark02.localdomain:42198
17/06/30 08:32:06 INFO TaskSetManager: Finished task 1.0 in stage 26.0 (TID 75) in 24727 ms on sd-spark02.localdomain (1/3)
17/06/30 08:32:08 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 76) in 26888 ms on sd-spark04.localdomain (2/3)
17/06/30 08:32:08 INFO TaskSetManager: Finished task 2.0 in stage 26.0 (TID 77) in 27121 ms on sd-spark04.localdomain (3/3)
17/06/30 08:32:08 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/06/30 08:32:08 INFO DAGScheduler: ShuffleMapStage 26 (flatMap at ALS.scala:1170) finished in 27.122 s
17/06/30 08:32:08 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:32:08 INFO DAGScheduler: running: Set()
17/06/30 08:32:08 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 27, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:32:08 INFO DAGScheduler: failed: Set()
17/06/30 08:32:08 INFO DAGScheduler: Submitting ShuffleMapStage 27 (MapPartitionsRDD[165] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:32:08 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 23.8 KB, free 624.4 KB)
17/06/30 08:32:08 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 7.3 KB, free 631.7 KB)
17/06/30 08:32:08 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 163.221.29.42:45435 (size: 7.3 KB, free: 511.0 MB)
17/06/30 08:32:08 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1006
17/06/30 08:32:08 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 27 (MapPartitionsRDD[165] at flatMap at ALS.scala:1170)
17/06/30 08:32:08 INFO TaskSchedulerImpl: Adding task set 27.0 with 3 tasks
17/06/30 08:32:08 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 78, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:08 INFO TaskSetManager: Starting task 1.0 in stage 27.0 (TID 79, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:08 INFO TaskSetManager: Starting task 2.0 in stage 27.0 (TID 80, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:08 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on sd-spark02.localdomain:36253 (size: 7.3 KB, free: 4.8 GB)
17/06/30 08:32:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to sd-spark02.localdomain:42198
17/06/30 08:32:08 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 17 is 174 bytes
17/06/30 08:32:08 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on sd-spark04.localdomain:42799 (size: 7.3 KB, free: 4.8 GB)
17/06/30 08:32:08 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 17 to sd-spark04.localdomain:40512
17/06/30 08:32:36 INFO TaskSetManager: Finished task 1.0 in stage 27.0 (TID 79) in 27536 ms on sd-spark04.localdomain (1/3)
17/06/30 08:32:39 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 78) in 30535 ms on sd-spark02.localdomain (2/3)
17/06/30 08:32:39 INFO TaskSetManager: Finished task 2.0 in stage 27.0 (TID 80) in 30562 ms on sd-spark02.localdomain (3/3)
17/06/30 08:32:39 INFO DAGScheduler: ShuffleMapStage 27 (flatMap at ALS.scala:1170) finished in 30.562 s
17/06/30 08:32:39 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:32:39 INFO DAGScheduler: running: Set()
17/06/30 08:32:39 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/06/30 08:32:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 28, ShuffleMapStage 29)
17/06/30 08:32:39 INFO DAGScheduler: failed: Set()
17/06/30 08:32:39 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[174] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:32:39 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 24.7 KB, free 656.4 KB)
17/06/30 08:32:39 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.5 KB, free 663.9 KB)
17/06/30 08:32:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 163.221.29.42:45435 (size: 7.5 KB, free: 511.0 MB)
17/06/30 08:32:39 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1006
17/06/30 08:32:39 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[174] at flatMap at ALS.scala:1170)
17/06/30 08:32:39 INFO TaskSchedulerImpl: Adding task set 28.0 with 3 tasks
17/06/30 08:32:39 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 81, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:39 INFO TaskSetManager: Starting task 1.0 in stage 28.0 (TID 82, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:39 INFO TaskSetManager: Starting task 2.0 in stage 28.0 (TID 83, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:32:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on sd-spark04.localdomain:42799 (size: 7.5 KB, free: 4.8 GB)
17/06/30 08:32:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to sd-spark04.localdomain:40512
17/06/30 08:32:39 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 16 is 171 bytes
17/06/30 08:32:39 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on sd-spark02.localdomain:36253 (size: 7.5 KB, free: 4.8 GB)
17/06/30 08:32:39 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 16 to sd-spark02.localdomain:42198
17/06/30 08:33:03 INFO TaskSetManager: Finished task 1.0 in stage 28.0 (TID 82) in 24560 ms on sd-spark02.localdomain (1/3)
17/06/30 08:33:05 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 81) in 26381 ms on sd-spark04.localdomain (2/3)
17/06/30 08:33:05 INFO TaskSetManager: Finished task 2.0 in stage 28.0 (TID 83) in 26480 ms on sd-spark04.localdomain (3/3)
17/06/30 08:33:05 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/06/30 08:33:05 INFO DAGScheduler: ShuffleMapStage 28 (flatMap at ALS.scala:1170) finished in 26.482 s
17/06/30 08:33:05 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:33:05 INFO DAGScheduler: running: Set()
17/06/30 08:33:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36, ShuffleMapStage 29)
17/06/30 08:33:05 INFO DAGScheduler: failed: Set()
17/06/30 08:33:05 INFO DAGScheduler: Submitting ShuffleMapStage 29 (MapPartitionsRDD[183] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:33:05 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 25.6 KB, free 689.4 KB)
17/06/30 08:33:05 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 7.6 KB, free 697.1 KB)
17/06/30 08:33:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 163.221.29.42:45435 (size: 7.6 KB, free: 511.0 MB)
17/06/30 08:33:05 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:1006
17/06/30 08:33:05 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 29 (MapPartitionsRDD[183] at flatMap at ALS.scala:1170)
17/06/30 08:33:05 INFO TaskSchedulerImpl: Adding task set 29.0 with 3 tasks
17/06/30 08:33:05 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 84, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:05 INFO TaskSetManager: Starting task 1.0 in stage 29.0 (TID 85, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:05 INFO TaskSetManager: Starting task 2.0 in stage 29.0 (TID 86, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on sd-spark02.localdomain:36253 (size: 7.6 KB, free: 4.8 GB)
17/06/30 08:33:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to sd-spark02.localdomain:42198
17/06/30 08:33:05 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 15 is 176 bytes
17/06/30 08:33:05 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on sd-spark04.localdomain:42799 (size: 7.6 KB, free: 4.8 GB)
17/06/30 08:33:05 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 15 to sd-spark04.localdomain:40512
17/06/30 08:33:33 INFO TaskSetManager: Finished task 1.0 in stage 29.0 (TID 85) in 27323 ms on sd-spark04.localdomain (1/3)
17/06/30 08:33:35 INFO TaskSetManager: Finished task 2.0 in stage 29.0 (TID 86) in 30051 ms on sd-spark02.localdomain (2/3)
17/06/30 08:33:36 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 84) in 30384 ms on sd-spark02.localdomain (3/3)
17/06/30 08:33:36 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/06/30 08:33:36 INFO DAGScheduler: ShuffleMapStage 29 (flatMap at ALS.scala:1170) finished in 30.384 s
17/06/30 08:33:36 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:33:36 INFO DAGScheduler: running: Set()
17/06/30 08:33:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 30, ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)
17/06/30 08:33:36 INFO DAGScheduler: failed: Set()
17/06/30 08:33:36 INFO DAGScheduler: Submitting ShuffleMapStage 30 (MapPartitionsRDD[192] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:33:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 26.4 KB, free 723.5 KB)
17/06/30 08:33:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.9 KB, free 731.4 KB)
17/06/30 08:33:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 163.221.29.42:45435 (size: 7.9 KB, free: 511.0 MB)
17/06/30 08:33:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1006
17/06/30 08:33:36 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 30 (MapPartitionsRDD[192] at flatMap at ALS.scala:1170)
17/06/30 08:33:36 INFO TaskSchedulerImpl: Adding task set 30.0 with 3 tasks
17/06/30 08:33:36 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 87, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:36 INFO TaskSetManager: Starting task 1.0 in stage 30.0 (TID 88, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:36 INFO TaskSetManager: Starting task 2.0 in stage 30.0 (TID 89, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:33:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on sd-spark04.localdomain:42799 (size: 7.9 KB, free: 4.8 GB)
17/06/30 08:33:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to sd-spark04.localdomain:40512
17/06/30 08:33:36 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 14 is 171 bytes
17/06/30 08:33:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on sd-spark02.localdomain:36253 (size: 7.9 KB, free: 4.8 GB)
17/06/30 08:33:36 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 14 to sd-spark02.localdomain:42198
17/06/30 08:34:01 INFO TaskSetManager: Finished task 1.0 in stage 30.0 (TID 88) in 24920 ms on sd-spark02.localdomain (1/3)
17/06/30 08:34:02 INFO TaskSetManager: Finished task 2.0 in stage 30.0 (TID 89) in 26228 ms on sd-spark04.localdomain (2/3)
17/06/30 08:34:02 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 87) in 26700 ms on sd-spark04.localdomain (3/3)
17/06/30 08:34:02 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/06/30 08:34:02 INFO DAGScheduler: ShuffleMapStage 30 (flatMap at ALS.scala:1170) finished in 26.700 s
17/06/30 08:34:02 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:34:02 INFO DAGScheduler: running: Set()
17/06/30 08:34:02 INFO DAGScheduler: waiting: Set(ShuffleMapStage 31, ShuffleMapStage 32, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)
17/06/30 08:34:02 INFO DAGScheduler: failed: Set()
17/06/30 08:34:02 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[201] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:34:02 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 27.3 KB, free 758.7 KB)
17/06/30 08:34:02 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 766.7 KB)
17/06/30 08:34:02 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 163.221.29.42:45435 (size: 8.0 KB, free: 511.0 MB)
17/06/30 08:34:02 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1006
17/06/30 08:34:02 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[201] at flatMap at ALS.scala:1170)
17/06/30 08:34:02 INFO TaskSchedulerImpl: Adding task set 31.0 with 3 tasks
17/06/30 08:34:02 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 90, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:02 INFO TaskSetManager: Starting task 1.0 in stage 31.0 (TID 91, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:02 INFO TaskSetManager: Starting task 2.0 in stage 31.0 (TID 92, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:02 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on sd-spark04.localdomain:42799 (size: 8.0 KB, free: 4.8 GB)
17/06/30 08:34:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to sd-spark04.localdomain:40512
17/06/30 08:34:02 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 13 is 174 bytes
17/06/30 08:34:02 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on sd-spark02.localdomain:36253 (size: 8.0 KB, free: 4.8 GB)
17/06/30 08:34:02 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 13 to sd-spark02.localdomain:42198
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 163.221.29.42:45435 in memory (size: 7.3 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on sd-spark04.localdomain:42799 in memory (size: 7.3 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_23_piece0 on sd-spark02.localdomain:36253 in memory (size: 7.3 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 163.221.29.42:45435 in memory (size: 7.2 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on sd-spark04.localdomain:42799 in memory (size: 7.2 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_22_piece0 on sd-spark02.localdomain:36253 in memory (size: 7.2 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 163.221.29.42:45435 in memory (size: 6.9 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_21_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 163.221.29.42:45435 in memory (size: 6.8 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.8 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.8 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 163.221.29.42:45435 in memory (size: 6.6 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_19_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 163.221.29.42:45435 in memory (size: 6.5 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.5 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_18_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.5 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 163.221.29.42:45435 in memory (size: 6.3 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.3 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_17_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.3 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 163.221.29.42:45435 in memory (size: 6.1 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on sd-spark04.localdomain:42799 in memory (size: 6.1 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_16_piece0 on sd-spark02.localdomain:36253 in memory (size: 6.1 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 163.221.29.42:45435 in memory (size: 5.9 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_15_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 163.221.29.42:45435 in memory (size: 5.7 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.7 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_14_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.7 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 163.221.29.42:45435 in memory (size: 5.6 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_13_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 163.221.29.42:45435 in memory (size: 5.4 KB, free: 511.0 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.4 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_12_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.4 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 163.221.29.42:45435 in memory (size: 5.2 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.2 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_11_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.2 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 163.221.29.42:45435 in memory (size: 5.0 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on sd-spark04.localdomain:42799 in memory (size: 5.0 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_10_piece0 on sd-spark02.localdomain:36253 in memory (size: 5.0 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 163.221.29.42:45435 in memory (size: 4.8 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on sd-spark04.localdomain:42799 in memory (size: 4.8 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_9_piece0 on sd-spark02.localdomain:36253 in memory (size: 4.8 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 163.221.29.42:45435 in memory (size: 4.6 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on sd-spark04.localdomain:42799 in memory (size: 4.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_8_piece0 on sd-spark02.localdomain:36253 in memory (size: 4.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 163.221.29.42:45435 in memory (size: 3.9 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_7_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 163.221.29.42:45435 in memory (size: 3.7 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_6_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.7 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 163.221.29.42:45435 in memory (size: 7.9 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on sd-spark04.localdomain:42799 in memory (size: 7.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_26_piece0 on sd-spark02.localdomain:36253 in memory (size: 7.9 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 163.221.29.42:45435 in memory (size: 7.6 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on sd-spark04.localdomain:42799 in memory (size: 7.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on sd-spark02.localdomain:36253 in memory (size: 7.6 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 163.221.29.42:45435 in memory (size: 7.5 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on sd-spark04.localdomain:42799 in memory (size: 7.5 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_24_piece0 on sd-spark02.localdomain:36253 in memory (size: 7.5 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO ContextCleaner: Cleaned accumulator 3
17/06/30 08:34:04 INFO ContextCleaner: Cleaned accumulator 2
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 163.221.29.42:45435 in memory (size: 3.0 KB, free: 511.1 MB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sd-spark06.localdomain:42959 in memory (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sd-spark05.localdomain:38332 in memory (size: 3.0 KB, free: 5.5 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sd-spark04.localdomain:42799 in memory (size: 3.0 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on sd-spark02.localdomain:36253 in memory (size: 3.0 KB, free: 4.8 GB)
17/06/30 08:34:04 INFO ContextCleaner: Cleaned accumulator 1
17/06/30 08:34:30 INFO TaskSetManager: Finished task 1.0 in stage 31.0 (TID 91) in 27266 ms on sd-spark04.localdomain (1/3)
17/06/30 08:34:31 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 90) in 29174 ms on sd-spark02.localdomain (2/3)
17/06/30 08:34:33 INFO TaskSetManager: Finished task 2.0 in stage 31.0 (TID 92) in 30249 ms on sd-spark02.localdomain (3/3)
17/06/30 08:34:33 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/06/30 08:34:33 INFO DAGScheduler: ShuffleMapStage 31 (flatMap at ALS.scala:1170) finished in 30.252 s
17/06/30 08:34:33 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:34:33 INFO DAGScheduler: running: Set()
17/06/30 08:34:33 INFO DAGScheduler: waiting: Set(ShuffleMapStage 32, ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)
17/06/30 08:34:33 INFO DAGScheduler: failed: Set()
17/06/30 08:34:33 INFO DAGScheduler: Submitting ShuffleMapStage 32 (MapPartitionsRDD[210] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:34:33 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 28.2 KB, free 291.7 KB)
17/06/30 08:34:33 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 8.2 KB, free 299.9 KB)
17/06/30 08:34:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 163.221.29.42:45435 (size: 8.2 KB, free: 511.1 MB)
17/06/30 08:34:33 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:1006
17/06/30 08:34:33 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 32 (MapPartitionsRDD[210] at flatMap at ALS.scala:1170)
17/06/30 08:34:33 INFO TaskSchedulerImpl: Adding task set 32.0 with 3 tasks
17/06/30 08:34:33 INFO TaskSetManager: Starting task 1.0 in stage 32.0 (TID 93, sd-spark02.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:33 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 94, sd-spark04.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:33 INFO TaskSetManager: Starting task 2.0 in stage 32.0 (TID 95, sd-spark04.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on sd-spark04.localdomain:42799 (size: 8.2 KB, free: 4.8 GB)
17/06/30 08:34:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to sd-spark04.localdomain:40512
17/06/30 08:34:33 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 12 is 171 bytes
17/06/30 08:34:33 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on sd-spark02.localdomain:36253 (size: 8.2 KB, free: 4.8 GB)
17/06/30 08:34:33 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 12 to sd-spark02.localdomain:42198
17/06/30 08:34:57 INFO TaskSetManager: Finished task 1.0 in stage 32.0 (TID 93) in 24823 ms on sd-spark02.localdomain (1/3)
17/06/30 08:34:59 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 94) in 26332 ms on sd-spark04.localdomain (2/3)
17/06/30 08:34:59 INFO TaskSetManager: Finished task 2.0 in stage 32.0 (TID 95) in 26486 ms on sd-spark04.localdomain (3/3)
17/06/30 08:34:59 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/06/30 08:34:59 INFO DAGScheduler: ShuffleMapStage 32 (flatMap at ALS.scala:1170) finished in 26.486 s
17/06/30 08:34:59 INFO DAGScheduler: looking for newly runnable stages
17/06/30 08:34:59 INFO DAGScheduler: running: Set()
17/06/30 08:34:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 37, ShuffleMapStage 38, ShuffleMapStage 39, ShuffleMapStage 40, ResultStage 41, ShuffleMapStage 33, ShuffleMapStage 34, ShuffleMapStage 35, ShuffleMapStage 36)
17/06/30 08:34:59 INFO DAGScheduler: failed: Set()
17/06/30 08:34:59 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[219] at flatMap at ALS.scala:1170), which has no missing parents
17/06/30 08:34:59 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 29.1 KB, free 328.9 KB)
17/06/30 08:34:59 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.3 KB, free 337.3 KB)
17/06/30 08:34:59 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 163.221.29.42:45435 (size: 8.3 KB, free: 511.1 MB)
17/06/30 08:34:59 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1006
17/06/30 08:34:59 INFO DAGScheduler: Submitting 3 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[219] at flatMap at ALS.scala:1170)
17/06/30 08:34:59 INFO TaskSchedulerImpl: Adding task set 33.0 with 3 tasks
17/06/30 08:34:59 INFO TaskSetManager: Starting task 1.0 in stage 33.0 (TID 96, sd-spark04.localdomain, partition 1,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:59 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 97, sd-spark02.localdomain, partition 0,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:59 INFO TaskSetManager: Starting task 2.0 in stage 33.0 (TID 98, sd-spark02.localdomain, partition 2,PROCESS_LOCAL, 2253 bytes)
17/06/30 08:34:59 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on sd-spark04.localdomain:42799 (size: 8.3 KB, free: 4.8 GB)
17/06/30 08:34:59 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on sd-spark02.localdomain:36253 (size: 8.3 KB, free: 4.8 GB)
17/06/30 08:34:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to sd-spark04.localdomain:40512
17/06/30 08:34:59 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 11 is 176 bytes
17/06/30 08:34:59 INFO MapOutputTrackerMasterEndpoint: Asked to send map output locations for shuffle 11 to sd-spark02.localdomain:42198
17/06/30 08:35:13 INFO SparkContext: Invoking stop() from shutdown hook
17/06/30 08:35:13 INFO SparkUI: Stopped Spark web UI at http://163.221.29.42:4050
17/06/30 08:35:13 INFO DAGScheduler: ShuffleMapStage 33 (flatMap at ALS.scala:1170) failed in 14.072 s
17/06/30 08:35:13 INFO SparkDeploySchedulerBackend: Shutting down all executors
17/06/30 08:35:13 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
17/06/30 08:35:13 INFO DAGScheduler: Job 2 failed: count at ALS.scala:263, took 641.230723 s
Exception in thread "main" org.apache.spark.SparkException: Job 2 cancelled because SparkContext was shut down
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:806)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$cleanUpAfterSchedulerStop$1.apply(DAGScheduler.scala:804)
	at scala.collection.mutable.HashSet.foreach(HashSet.scala:79)
	at org.apache.spark.scheduler.DAGScheduler.cleanUpAfterSchedulerStop(DAGScheduler.scala:804)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onStop(DAGScheduler.scala:1658)
	at org.apache.spark.util.EventLoop.stop(EventLoop.scala:84)
	at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1581)
	at org.apache.spark.SparkContext$$anonfun$stop$7.apply$mcV$sp(SparkContext.scala:1731)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1229)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1730)
	at org.apache.spark.SparkContext$$anonfun$3.apply$mcV$sp(SparkContext.scala:596)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:267)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1741)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:239)
	at scala.util.Try$.apply(Try.scala:161)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:239)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:218)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:620)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1832)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1845)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1858)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1929)
	at org.apache.spark.rdd.RDD.count(RDD.scala:1143)
	at org.apache.spark.mllib.recommendation.ALS.run(ALS.scala:263)
	at org.apache.spark.mllib.recommendation.ALS$.train(ALS.scala:328)
	at org.apache.spark.mllib.recommendation.ALS$.train(ALS.scala:346)
	at S55_000_000_T$.main(S55_000_000_T.scala:14)
	at S55_000_000_T.main(S55_000_000_T.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/06/30 08:35:14 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/06/30 08:35:14 INFO MemoryStore: MemoryStore cleared
17/06/30 08:35:14 INFO BlockManager: BlockManager stopped
17/06/30 08:35:14 INFO BlockManagerMaster: BlockManagerMaster stopped
17/06/30 08:35:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/06/30 08:35:15 INFO SparkContext: Successfully stopped SparkContext
17/06/30 08:35:15 INFO ShutdownHookManager: Shutdown hook called
17/06/30 08:35:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-2bcef316-5eac-48e1-bb65-5da882d4d127
17/06/30 08:35:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-2bcef316-5eac-48e1-bb65-5da882d4d127/httpd-810a3b77-dd7e-4889-8d7b-8919bf2c5057
17/06/30 08:35:15 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/06/30 08:35:15 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
